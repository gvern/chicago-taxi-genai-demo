# ML Pipeline Configuration - Forecasting with Vertex AI

gcp:
  project_id: "avisia-certification-ml-yde"
  region: "europe-west1"
  dataset_id: "chicago_taxi_data"


bigquery:
  dataset_id: "chicago_taxis" # Dataset for pipeline outputs (training table, prediction input/output)
  source_table_id: "bigquery-public-data.chicago_taxi_trips.taxi_trips" # Source for raw data (used by SQL query)
  training_table_name: "demand_by_hour" # Name for the generated training table
  prediction_input_table_name: "forecast_input" # Name for the generated prediction input table
  prediction_output_prefix: "forecast_output" # Prefix for batch prediction output table

# Forecasting Configuration
forecasting:
  time_column: timestamp_hour
  target_column: trip_count
  context_column: pickup_community_area
  time_granularity: "hour"
  forecast_horizon: 24
  window_size: 168              # Taille du contexte historique utilisé
  available_at_forecast:        # Toutes ces colonnes sont connues à l'avance (calculables pour l'avenir)
    - timestamp_hour
    - day_of_year
    - day_of_week
    - hour
    - month
    - is_weekend
    - hour_sin
    - hour_cos
    - year
    - pickup_community_area
  unavailable_at_forecast:      # Connue uniquement dans le passé
    - trip_count
  time_window:
    end_date: "2023-11-22" # Date de fin souhaitée pour les données d'entraînement/test
    max_data_points: 2950 
data_preprocessing:
  sql_template_path: "src/data_preprocessing/bigquery_queries.sql"
  time_window:
    end_date_str: "2023-11-22" # End date for training data generation
    max_data_points: 2950 # Max number of hours per series for training data
# Vertex AI Forecast Model Parameters
vertex_ai_forecast:
  display_name: "chicago_taxi_forecast_model"
  optimization_objective: "minimize-rmse"
  budget_milli_node_hours: 8000    # ~1h d'entraînement
  column_transformations:
    timestamp_hour: "timestamp"
    pickup_community_area: "categorical"
    trip_count: "numeric"
    hour: "numeric"
    day_of_week: "categorical"
    month: "categorical"
    day_of_year: "numeric"
    is_weekend: "categorical"
    hour_sin: "numeric"
    hour_cos: "numeric"
    year: "numeric"


  hyperparameters:
    learning_rate: 0.01
    batch_size: 32
    num_epochs: 50
    early_stopping: true
    patience: 5
    dropout_rate: 0.2
  model_type: "ARIMA"           # Choix du modèle
  model_selection:
    - "AutoML"
    - "XGBoost"
    - "ARIMA"
    - "Prophet"
  model_selection_criteria: "rmse" # Critère de sélection du modèle
  model_selection_timeout: 3600   # Timeout pour la sélection du modèle
  model_selection_max_trials: 10  # Nombre maximum d'essais pour la sélection du modèle
  model_selection_max_parallel_trials: 2 # Nombre maximum d'essais parallèles

  predefined_split_column_name: null
  time_column: "timestamp_hour"
  time_series_identifier_column: "pickup_community_area"
  training_fraction_split: 0.8
  validation_fraction_split: 0.1
  test_fraction_split: 0.1

# Evaluation Metrics (après prédiction)
evaluation:
  metrics:
    - rmse
    - mae
    - r2
  threshold:
    rmse: 5.0
    mae: 4.0
    r2: 0.7

# Deployment Parameters (si modèle batch ou endpoint)
deployment:
  model_name: "chicago_taxi_demand"
  version: "v1"
  min_instances: 1
  max_instances: 10
  machine_type: "n1-standard-2"

# Monitoring Thresholds
monitoring:
  prediction_threshold: 1000
  error_rate_threshold: 0.05
  latency_threshold: 200  # ms
  alert_email: "alerts@example.com"

# Resources
resources:
  cpu: 2
  memory: "8Gi"
  gpu: 0
  storage: "100Gi"
