# ML Pipeline Configuration - Forecasting with Vertex AI

# Data Processing Parameters
data_processing:
  sample_size: 1000000         # Optionnel pour les tests locaux
  random_seed: 42
  train_test_split: 0.8        # Peut être ignoré si Vertex AI gère les splits
  validation_split: 0.1

# Feature Engineering
feature_engineering:
  temporal_features:
    - hour
    - day_of_week
    - month
    - day_of_year
    - is_weekend
  spatial_features:
    - pickup_community_area
  exogenous_features:
    - temperature
    - precipitation
    - wind_speed

# Forecasting Configuration
forecasting:
  time_column: timestamp_hour
  target_column: trip_count
  context_column: pickup_community_area
  time_granularity: "hour"
  forecast_horizon: 24
  window_size: 168              # Taille du contexte historique utilisé
  available_at_forecast:        # Toutes ces colonnes sont connues à l'avance (calculables pour l'avenir)
    - timestamp_hour
    - day_of_year
    - day_of_week
    - hour
    - month
    - is_weekend
    - temperature
    - precipitation
    - wind_speed

  unavailable_at_forecast:      # Connue uniquement dans le passé
    - trip_count
  data_granularity_unit: hour

# Vertex AI Forecast Model Parameters
vertex_ai_forecast:
  display_name: "chicago_taxi_forecast_model"
  optimization_objective: "minimize-rmse"
  budget_milli_node_hours: 1000    # ~1h d'entraînement
  column_transformations:
    timestamp_hour: "timestamp"
    pickup_community_area: "categorical"
    trip_count: "numeric"
    hour: "numeric"
    day_of_week: "categorical"
    month: "categorical"
    day_of_year: "numeric"
    is_weekend: "categorical"
    temperature: "numeric"
    precipitation: "numeric"
    wind_speed: "numeric"

# Evaluation Metrics (après prédiction)
evaluation:
  metrics:
    - rmse
    - mae
    - r2
  threshold:
    rmse: 5.0
    mae: 4.0
    r2: 0.7

# Deployment Parameters (si modèle batch ou endpoint)
deployment:
  model_name: "chicago_taxi_demand"
  version: "v1"
  min_instances: 1
  max_instances: 10
  machine_type: "n1-standard-2"

# Monitoring Thresholds
monitoring:
  prediction_threshold: 1000
  error_rate_threshold: 0.05
  latency_threshold: 200  # ms
  alert_email: "alerts@example.com"

# Resources
resources:
  cpu: 2
  memory: "8Gi"
  gpu: 0
  storage: "100Gi"
