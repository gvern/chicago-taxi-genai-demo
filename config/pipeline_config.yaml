# Configuration for Custom Training + HPT Pipeline (v3 - Simple HPT Params & Consistent Keys)

gcp:
  project_id: "avisia-certification-ml-yde" # Remplacez par votre Project ID
  region: "europe-west1"
  staging_bucket: "gs://chicago-taxis-bucket/staging" # Remplacez par votre bucket GCS
  # URI de l'image Docker personnalisée pour les composants
  custom_image_uri: "europe-west1-docker.pkg.dev/avisia-certification-ml-yde/chicago-taxis-demo/forecasting-pipeline:latest"
  # Optionnel: Compte de service pour l'exécution du pipeline
  service_account: "491780955535-compute@developer.gserviceaccount.com"

bigquery:
  dataset_id: "chicago_taxis" # Dataset pour les tables générées
  source_table_id: "bigquery-public-data.chicago_taxi_trips.taxi_trips" # Table source brute (Clé corrigée)
  training_table_name: "demand_by_hour" # Nom de la table d'entraînement/préparée générée

data_preprocessing: # Section pour les paramètres de run_bq_forecasting_query
  sql_template_path: "src/pipelines/components/preprocessing/bigquery_queries.sql" # Chemin dans le conteneur
  time_window:
    end_date_str: "2023-11-22" # Date de fin pour l'extraction des données historiques
    max_data_points: 2950 # Max points historiques par série

training: # Section pour les paramètres liés à l'entraînement (script train_xgboost_hpt.py)
  time_column: "timestamp_hour"       # Correspond à 'train_time_column' dans le pipeline
  target_column: "trip_count"         # Correspond à 'train_target_column' dans le pipeline
  series_id_column: "pickup_community_area" # Correspond à 'train_series_id_column' dans le pipeline
  worker_machine_type: "n1-standard-4" # Correspond à 'worker_machine_type' dans le pipeline

# Paramètres de haut niveau utilisés par le pipeline
# (Placés ici pour correspondre à l'accès direct config.get(...) dans run_pipeline.py)
enable_hpt: False # Mettre à True pour activer HPT
train_end_date: "2023-10-01T00:00:00" # Correspond à 'train_end_date' dans le pipeline
val_end_date: "2023-11-22T00:00:00"   # Correspond à 'val_end_date' dans le pipeline
default_hyperparameters: # Correspond à 'default_hyperparameters' (utilisé si enable_hpt=False)
  n_estimators: 100
  learning_rate: 0.1
  max_depth: 5
  subsample: 0.8
  colsample_bytree: 0.8
  reg_lambda: 1.0 # Assurez-vous que tous les HPs par défaut nécessaires sont listés

hpt: # Section pour les paramètres généraux HPT (passés à launch_hpt_job)
  display_name_prefix: "xgboost-hpt-run" # Correspond à 'hpt_display_name_prefix'
  metric_tag: "rmse"                     # Correspond à 'hpt_metric_tag'
  metric_goal: "MINIMIZE"                # Correspond à 'hpt_metric_goal'
  max_trial_count: 10                    # Correspond à 'hpt_max_trial_count'
  parallel_trial_count: 2                # Correspond à 'hpt_parallel_trial_count'
  search_algorithm: "RANDOM_SEARCH"      # Correspond à 'hpt_search_algorithm'

hpt_params: # Section pour les paramètres *spécifiques* à régler par HPT
            # Correspond aux paramètres hpt_..._min/max/scale du pipeline
  n_estimators:
    min: 50
    max: 500
    scale: "UNIT_LINEAR_SCALE" # Doit être une valeur valide de l'enum aiplatform.ScaleType
  learning_rate:
    min: 0.01
    max: 0.3
    scale: "UNIT_LOG_SCALE"
  max_depth:
    min: 3
    max: 10
    scale: "UNIT_LINEAR_SCALE"
  reg_lambda:
    min: 0.1
    max: 10.0
    scale: "UNIT_LOG_SCALE"
  # Ajoutez ici les sections pour d'autres HPs si vous en ajoutez au pipeline/composant
  # subsample:
  #   min: 0.5
  #   max: 1.0
  #   scale: "UNIT_LINEAR_SCALE"
  # colsample_bytree:
  #   min: 0.5
  #   max: 1.0
  #   scale: "UNIT_LINEAR_SCALE"

prediction: # Section pour les paramètres de génération des features futures et prédiction batch
  gen_forecast_input_horizon_hours: 168 # Correspond à 'gen_forecast_input_horizon_hours'
  gen_forecast_input_start_time: ""    # Correspond à 'gen_forecast_input_start_time'
  batch_pred_output_suffix: "predictions/predictions.csv" # Correspond à 'batch_pred_output_suffix'

evaluation: # Section pour les paramètres d'évaluation
  eval_output_dir_suffix: "evaluation_output" # Correspond à 'eval_output_dir_suffix'

pipeline: # Section pour les paramètres généraux du pipeline
  activate_downstream_steps: True # Correspond à 'activate_downstream_steps'
  enable_caching: False           # Utilisé par run_pipeline.py

# Sections optionnelles ou non utilisées par le script run_pipeline.py fourni
# (gardées pour référence mais les accès devront être ajoutés si nécessaire)
# forecasting: ...
# custom_training: ... # Les clés statiques sont maintenant lues depuis 'training' et root
# batch_prediction: ... # Seul le suffixe est lu actuellement
# model_registry: ...