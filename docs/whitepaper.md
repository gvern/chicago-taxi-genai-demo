# ğŸ“„ Whitepaper â€“ Forecasting de la Demande de Taxis Ã  Chicago

## ğŸ¯ Executive Summary

Ce projet propose une solution de prÃ©vision horaire du volume de trajets de taxi dans la ville de Chicago, Ã  lâ€™Ã©chelle de chaque quartier (`pickup_community_area`). BasÃ© sur le service Vertex AI Forecast de Google Cloud, le pipeline permet dâ€™anticiper la demande pour optimiser lâ€™allocation des taxis, rÃ©duire les temps dâ€™attente des clients et mieux rÃ©pondre aux pics de trafic ou Ã©vÃ©nements.

La solution utilise BigQuery pour lâ€™agrÃ©gation Ã  grande Ã©chelle du dataset public Chicago Taxi Trips (187M+ lignes), intÃ¨gre les meilleures pratiques de scalabilitÃ©, de modÃ©lisation temporelle, et s'appuie sur une architecture moderne GCP de bout-en-bout.

## ğŸŒ Data Locations

This project utilizes the following data assets stored on Google Cloud:

*   **Project ID:** `avisia-certification-ml-yde`
*   **Region (Primary):** `us-central1` (used for Vertex AI resources and GCS bucket)
*   **Source Data:** BigQuery Public Dataset `bigquery-public-data.chicago_taxi_trips.taxi_trips`.
*   **Processed Data Location (BigQuery):** The final table used for training, generated by the pipeline's preprocessing step: `bq://avisia-certification-ml-yde.chicago_taxis.demand_by_hour` (in BigQuery's US multi-region location).
*   **Vertex AI Artifacts Location (GCS):** Bucket used for Vertex AI Pipeline root, model artifacts, and staging: `gs://avisia-certification-ml-yde-vertex-bucket`.
*   **Vertex AI Datasets:** TimeSeriesDatasets created by the pipeline, visible in the Vertex AI UI under the specified project and region.
*   **Vertex AI Models:** Trained AutoML Forecasting models registered in the Vertex AI Model Registry under the specified project and region.

---

## ğŸ’¼ Business Goal

Lâ€™objectif mÃ©tier principal est de permettre Ã  lâ€™opÃ©rateur de taxis de :

- **PrÃ©voir le volume de demandes par heure et par quartier**
- **Optimiser la rÃ©partition de la flotte de vÃ©hicules**
- **RÃ©duire les dÃ©lais dâ€™attente et les trajets Ã  vide**
- **Mieux gÃ©rer les jours fÃ©riÃ©s, Ã©vÃ©nements, et pÃ©riodes de forte demande**

---

## ğŸ”§ ML Use Case: Time Series Forecasting multi-sÃ©ries

- **Type de tÃ¢che :** PrÃ©vision de sÃ©ries temporelles (Forecasting)
- **Variable cible :** `trip_count` (nombre de trajets par heure)
- **Identifiant de sÃ©rie :** `pickup_community_area`
- **GranularitÃ© :** Horaire (`timestamp_hour`)
- **Horizon de prÃ©vision :** 24h (configurable)
- **Approche :** Forecasting multi-sÃ©ries automatisÃ© avec Vertex AI Forecast (AutoML)
- **MÃ©triques de rÃ©fÃ©rence :** RMSE, MAE, MAPE (WAPE, MASE)

---

## ğŸ“Š Data Exploration & Feature Engineering

### ğŸ” Exploration

- Analyse des sÃ©ries temporelles sur 1 an (tendances, saisonnalitÃ©)
- DÃ©tection des zones Ã  forte variabilitÃ© de demande
- Analyse des heures de pointe, jours fÃ©riÃ©s, jours de la semaine

### ğŸ› ï¸ Feature Engineering

- AgrÃ©gation BQ par `pickup_community_area Ã— timestamp_hour`
- GÃ©nÃ©ration des sÃ©ries complÃ¨tes via `GENERATE_TIMESTAMP_ARRAY`
- Encodage temporel :
  - `hour`, `day_of_week`, `month`, `is_weekend`, `is_holiday`
- IntÃ©gration exogÃ¨ne :
  - DonnÃ©es mÃ©tÃ©o (via API NOAA, optionnel)
  - Calendrier des Ã©vÃ©nements publics (optionnel)
- CrÃ©ation automatique des lags et fenÃªtres (par Vertex AI Forecast)

### ML.3.4.3.3 Feature Engineering

Feature engineering was primarily performed within BigQuery to leverage its scalability for processing the large dataset. The goal was to create a structured time series dataset suitable for Vertex AI Forecast.

**Key Steps:**

1.  **Aggregation:** Raw trip data was aggregated to calculate the hourly `trip_count` for each `pickup_community_area`.
2.  **Time Index Generation:** A complete sequence of hourly timestamps covering the entire period of the raw data was generated.
3.  **Cartesian Product & Filling:** A Cartesian product between all unique community areas and all hourly timestamps was created. This ensures a complete grid. The aggregated `trip_count` was then joined, filling missing combinations (hours/zones with no trips) with a `trip_count` of 0.
4.  **Temporal Feature Creation:** Standard temporal features were extracted directly from the `timestamp_hour`: `hour`, `day_of_week`, `month`, `year`, `day_of_year`.
5.  **Derived Temporal Features:** Simple binary flags like `is_weekend` and `is_holiday` (based on common US holidays) were created.
6.  **Lag/Window Features:** Vertex AI Forecast automatically generates lag features, window-based features (e.g., moving averages), and other time-series specific features during training. Therefore, these were not explicitly engineered in the BigQuery step.

**Final Features Provided to Vertex AI Forecast:**
*   `timestamp_hour`: (TIMESTAMP) The specific hour (time column).
*   `pickup_community_area`: (INTEGER/STRING) The identifier for each time series.
*   `trip_count`: (INTEGER) The target variable to forecast.
*   `hour`: (INTEGER) Hour of the day (0-23) - Captures daily cycles.
*   `day_of_week`: (INTEGER) Day of the week (e.g., 1-7 or 0-6) - Captures weekly cycles.
*   `month`: (INTEGER) Month of the year (1-12) - Captures yearly seasonality.
*   `year`: (INTEGER) Year.
*   `day_of_year`: (INTEGER) Day of the year (1-366).
*   `is_weekend`: (INTEGER/BOOLEAN) Flag for Saturday/Sunday.
*   `is_holiday`: (INTEGER/BOOLEAN) Flag for specific major holidays.

These features provide the model with essential information about the time context for each observation.

**Code Snippets Example (Illustrative from `bigquery_queries.sql`):**

*Generating all combinations and filling counts:*
```sql
-- 4. Generate Cartesian product (hour x zone)
all_combinations AS (
  SELECT
    h.timestamp_hour,
    a.pickup_community_area
  FROM all_hours h -- CTE generating all hourly timestamps
  CROSS JOIN areas a -- CTE with distinct pickup_community_area
),
-- 5. Count aggregated trips per hour x zone
aggregated AS (
  SELECT
    TIMESTAMP_TRUNC(trip_start_timestamp, HOUR) AS timestamp_hour,
    pickup_community_area,
    COUNT(*) AS trip_count
  FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`
  WHERE pickup_community_area IS NOT NULL
  GROUP BY 1, 2
),
-- 6. Join all combinations with aggregated data, fill missing with 0
filled AS (
  SELECT
    ac.timestamp_hour,
    ac.pickup_community_area,
    IFNULL(agg.trip_count, 0) AS trip_count
  FROM all_combinations ac
  LEFT JOIN aggregated agg
    ON ac.timestamp_hour = agg.timestamp_hour
   AND ac.pickup_community_area = agg.pickup_community_area
)
```

*Extracting temporal features:*
```sql
-- 7. Add temporal features
SELECT
  timestamp_hour,
  pickup_community_area,
  trip_count,
  EXTRACT(HOUR FROM timestamp_hour) AS hour,
  EXTRACT(DAYOFWEEK FROM timestamp_hour) AS day_of_week, -- Note: BQ specific day numbering
  EXTRACT(MONTH FROM timestamp_hour) AS month,
  EXTRACT(YEAR FROM timestamp_hour) AS year,
  EXTRACT(DAYOFYEAR FROM timestamp_hour) AS day_of_year,
  IF(EXTRACT(DAYOFWEEK FROM timestamp_hour) IN (1, 7), 1, 0) AS is_weekend, -- Adjust if necessary
  IF(FORMAT_DATE('%m-%d', DATE(timestamp_hour)) IN ('01-01', '07-04', '12-25'), 1, 0) AS is_holiday -- Simple heuristic
FROM filled
ORDER BY timestamp_hour, pickup_community_area;
```
(Full query: `src/data_preprocessing/bigquery_queries.sql`)

### ML.3.4.3.2 Data Exploration

**Process:**
Initial data exploration was crucial to understand the structure, quality, and characteristics of the raw Chicago Taxi Trips data. This involved:

1.  **Sampling:** Due to the large volume (187M+ rows), initial exploration was performed on a representative sample obtained directly from BigQuery.
2.  **Descriptive Statistics:** Calculating basic statistics (count, mean, min, max, quartiles) for key numerical columns like `trip_miles`, `trip_seconds`.
3.  **Distribution Analysis:** Visualizing the distribution of trips over time (years, months, days, hours), trip duration, trip distance, and fares.
4.  **Categorical Analysis:** Examining the distribution of pickups and dropoffs across community areas.
5.  **Time Series Visualization:** Plotting the aggregated hourly demand per community area to identify trends, seasonality (daily, weekly, yearly), and potential outliers or anomalies.
6.  **Correlation Analysis:** Investigating potential relationships between demand and temporal features (hour, day of week, holidays).

**Tools Used:**
*   Google BigQuery (for sampling and initial aggregation)
*   Vertex AI Workbench (Jupyter environment)
*   Python Libraries:
    *   `google-cloud-bigquery` (to interact with BigQuery)
    *   `pandas` (for data manipulation and analysis)
    *   `matplotlib` & `seaborn` (for visualization)

**Key Findings & Influence on Decisions:**
*   **Strong Seasonality:** Clear daily and weekly patterns were observed in taxi demand, confirming the need for time-based features.
*   **Varying Zone Behavior:** Different community areas exhibited significantly different demand patterns and volumes, justifying a multi-time-series approach (forecasting per `pickup_community_area`).
*   **Data Completeness:** While generally good, some fields like `pickup_community_area` had null values that needed filtering.
*   **Outliers:** Some trips had unusually long durations or distances, which were considered but ultimately included as they might represent valid edge cases or data entry issues that the model should be robust to (or handled by BQ aggregation).
*   **Need for Full Time Index:** Simple aggregation revealed gaps in the time series (hours with zero trips for a given zone). This highlighted the necessity of creating a complete time index (all hours for all zones) and filling missing values (with 0 trips) during preprocessing, which is handled in the `bigquery_queries.sql`.

**Code Snippets Example (Illustrative):**

*Fetching a sample from BigQuery:*
```python
# In a Vertex AI Workbench Notebook
from google.cloud import bigquery
import pandas as pd

client = bigquery.Client(project='avisia-certification-ml-yde')

# Query to get a recent sample
sample_query = f"""
SELECT
    trip_start_timestamp,
    pickup_community_area,
    trip_miles,
    trip_seconds
FROM
    `bigquery-public-data.chicago_taxi_trips.taxi_trips`
WHERE
    pickup_community_area IS NOT NULL
    AND trip_start_timestamp >= '2022-01-01' # Example filter
LIMIT 100000
"""
sample_df = client.query(sample_query).to_dataframe()

print(sample_df.info())
print(sample_df.describe())
```

*Basic Time Series Plotting (after aggregation):*
```python
# Assuming 'hourly_demand_df' is a pandas DataFrame with
# index='timestamp_hour', columns='pickup_community_area', values='trip_count'
import matplotlib.pyplot as plt
import seaborn as sns

# Select a specific area to plot
area_to_plot = 6 # Example area
demand_subset = hourly_demand_df[area_to_plot].loc['2022-01-01':'2022-01-31'] # Example date range

plt.figure(figsize=(15, 6))
sns.lineplot(data=demand_subset)
plt.title(f'Hourly Taxi Demand - Area {area_to_plot} (Jan 2022)')
plt.xlabel('Timestamp')
plt.ylabel('Trip Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```
(Detailed exploration notebooks: `notebooks/1_EDA.ipynb`, `notebooks/eda_chicago_taxi_v3_bigquery.ipynb`)

### ML.3.4.3.4 Preprocessing and the Data Pipeline

**Pipeline Overview:**
The primary data preprocessing pipeline is implemented as a single, comprehensive BigQuery SQL query (`src/data_preprocessing/bigquery_queries.sql`). This query transforms the raw taxi trip data into the final `demand_by_hour` table, ready for consumption by Vertex AI Forecast.

**Orchestration:**
This BigQuery-based preprocessing step is orchestrated as part of a larger MLOps workflow using **Vertex AI Pipelines** (built on Kubeflow Pipelines). A dedicated KFP component (`src/pipelines/components/run_bq_forecasting_query.py`) is responsible for executing the BigQuery query.

**Why BigQuery?**
BigQuery was chosen for preprocessing due to:
*   **Scalability:** Easily handles the large volume of the Chicago Taxi dataset without requiring manual cluster management.
*   **SQL Interface:** Allows complex aggregations, joins, and feature engineering logic to be expressed declaratively in SQL.
*   **Integration:** Seamlessly integrates with Vertex AI Datasets, allowing Vertex AI Forecast to read directly from the resulting BigQuery table.

*(Alternative: While a Dataflow pipeline (`src/data_preprocessing/dataflow_pipeline.py`) exists in the repository for potential row-level processing, the primary path for this forecasting demo relies solely on BigQuery for the necessary aggregation and feature engineering.)*

**Callable API/Function:**
The preprocessing step is made "callable" within the Vertex AI Pipeline through the KFP component. This component takes parameters like `project_id`, `location`, `dataset_id`, and `destination_table` and executes the embedded SQL query.

**Code Snippets Example:**

*Core Aggregation Logic Snippet (from `src/data_preprocessing/bigquery_queries.sql`):*
```sql
-- Simplified view of the core transformation within the CTE structure
CREATE OR REPLACE TABLE `{project_id}.{dataset_id}.{destination_table}` AS
WITH
  -- (CTEs for generating all_hours and all_areas)
  all_combinations AS (...),
  aggregated AS (
    SELECT
      TIMESTAMP_TRUNC(trip_start_timestamp, HOUR) AS timestamp_hour,
      pickup_community_area,
      COUNT(*) AS trip_count
    FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`
    WHERE pickup_community_area IS NOT NULL
    GROUP BY 1, 2
  ),
  filled AS (
    SELECT
      ac.timestamp_hour,
      ac.pickup_community_area,
      IFNULL(agg.trip_count, 0) AS trip_count
    FROM all_combinations ac
    LEFT JOIN aggregated agg USING(timestamp_hour, pickup_community_area)
  )
-- Final SELECT adding temporal features (hour, day_of_week, etc.)
SELECT ... FROM filled ORDER BY ...;
```

*KFP Component Invocation Snippet (from `src/pipelines/forecasting_pipeline.py`):*
```python
from src.pipelines.components.run_bq_forecasting_query import run_bq_forecasting_query
# ... other imports and pipeline definition ...

@dsl.pipeline(...)
def forecasting_pipeline(
    project: str,
    location: str,
    bq_output_uri: str,
    # ... other parameters
):
    # Step 1: Generate the final BigQuery table using the component
    prep_step = run_bq_forecasting_query(
        project_id=project,
        location=location,
        # dataset_id and destination_table use component defaults or can be passed
        # The component returns the table URI upon completion
    )
    # The output table BQ_URI (e.g., bq://project.dataset.table)
    # is then used as input for the next step (creating Vertex AI Dataset)
```
This demonstrates how the SQL logic is encapsulated and invoked programmatically within the pipeline.

### ML.3.4.3.5 Machine Learning Model Design(s) and Selection

**Model Selected:** Vertex AI Forecast (using AutoML)

**Rationale for Selection:**
Vertex AI Forecast (AutoML) was chosen for this multi-time-series forecasting task due to several advantages:

*   **Automated Feature Engineering:** Handles complex time-series feature engineering internally (lags, windows, embeddings, etc.), reducing manual effort.
*   **Algorithm Selection & HPO:** Automatically tests various state-of-the-art forecasting algorithms (like Temporal Fusion Transformers, ARIMA+, etc.) and performs hyperparameter optimization within the allocated budget.
*   **Scalability:** Built to handle large datasets and a high number of time series (in this case, one per community area).
*   **Ease of Use:** Simplifies the training process through the Vertex AI SDK and UI, allowing focus on the problem definition rather than low-level implementation details.
*   **Integration:** Natively integrates with Vertex AI Datasets, Model Registry, and Batch Prediction services.
*   **Best Practices:** Incorporates best practices for time series splitting and evaluation automatically.

**Alternative Models Considered (Briefly):**
*   **Custom Models (e.g., XGBoost, LSTM):** While powerful, these would require significant manual feature engineering (especially for lags/windows), careful handling of multiple time series, and manual HPO, increasing complexity and development time.
*   **Traditional Statistical Models (ARIMA, Prophet):** Might struggle with the large number of series and potentially complex interactions that AutoML can capture.

**Code Snippet Example (Illustrative - KFP Component Call):**

*Initializing and running the AutoML Training Job (from `src/pipelines/components/train_forecasting_model.py` via `forecasting_pipeline.py`):
```python
# Within the KFP component train_forecasting_model.py
from google.cloud import aiplatform

def train_forecasting_model(
    project: str,
    location: str,
    display_name: str,
    dataset_resource_name: Input[Artifact],
    target_column: str,
    time_column: str,
    time_series_identifier_column: str,
    forecast_horizon: int,
    context_window: int,
    # ... other params like granularity, optimization_objective, budget
):
    aiplatform.init(project=project, location=location)

    # Define the AutoML Forecasting job
    job = aiplatform.AutoMLForecastingTrainingJob(
        display_name=f"{display_name}_training_job",
        optimization_objective=optimization_objective # e.g., "minimize-rmse"
    )

    # Launch the training job
    model = job.run(
        dataset=aiplatform.TimeSeriesDataset(dataset_resource_name.path.read()),
        target_column=target_column,
        time_column=time_column,
        time_series_identifier_column=time_series_identifier_column,
        forecast_horizon=forecast_horizon,
        context_window=context_window,
        # Transformations can be specified here if needed
        # transformation=[...]
        budget_milli_node_hours=budget_milli_node_hours,
        model_display_name=display_name
        # Other parameters like available/unavailable columns can be added
    )

    # Output the trained model's resource name
    # model_resource_name.path.open("w").write(model.resource_name)
    print(f"Model trained: {model.resource_name}")
```
This snippet shows the core SDK call used within the pipeline component to initiate the Vertex AI Forecast training process.

### ML.3.4.3.6 Machine Learning Model Training and Development

Model training is performed using Vertex AI Training, specifically leveraging the AutoML Forecasting capability orchestrated via a Vertex AI Pipeline.

**Training Environment:** Vertex AI Training (Serverless)

**Key Aspects:**

*   **Data Splitting (Sampling):** Vertex AI Forecast automatically handles data splitting for time series. By default, it uses a chronological split based on the time column. The typical splits configured (visible in `config/pipeline_config.yaml` or passed to the job) are often 80% for training, 10% for validation, and 10% for testing. This ensures the model is validated and tested on data points that occur *after* the training data, preventing data leakage from the future.
    *   *Code Snippet (Illustrative - Parameters affecting splits are part of `job.run`):* The `forecast_horizon` and `context_window` parameters implicitly define how data is used. Vertex AI determines the latest possible training data point based on the horizon needed for the first test point. Specific split fractions (`training_fraction_split`, `validation_fraction_split`, `test_fraction_split`) can also be set if default behavior needs overriding.
*   **Implementation & GCP Best Practices:**
    *   **Vertex AI SDK & Pipelines:** Training is invoked programmatically using the `google-cloud-aiplatform` SDK within a KFP component, facilitating MLOps automation and reproducibility.
    *   **Serverless Training:** AutoML training jobs run on Google-managed infrastructure, eliminating the need for manual provisioning or management of training clusters.
    *   **Artifact Management:** The trained model is automatically registered in the Vertex AI Model Registry, linking it to the training job and dataset.
    *   **Monitoring:** Training progress and resource consumption can be monitored via the Google Cloud Console (Vertex AI -> Training).
    *   *Code Snippet:* The `job.run(...)` call shown in the previous section (ML.3.4.3.5) represents the core implementation step following GCP best practices for managed ML training.
*   **Evaluation Metric:** The primary metric used for optimization is **Root Mean Squared Error (RMSE)** (`optimization_objective='minimize-rmse'`).
    *   **Rationale:** RMSE was chosen because it heavily penalizes large prediction errors. In the context of taxi demand, underestimating demand significantly during peak hours (leading to large errors) could result in poor service and lost revenue, making it important to minimize these large deviations. Other metrics like MAE or MAPE are also calculated by Vertex AI and can be used for supplementary evaluation.
*   **Hyperparameter Optimization (HPO):** Vertex AI AutoML internally performs HPO. It searches through different model architectures and hyperparameters within the constraints of the allocated training budget (`budget_milli_node_hours`). The specific algorithms and search space are managed by Google.
    *   *Code Snippet (Illustrative - Budget Parameter):* The budget is specified during the `job.run` call:
        ```python
        model = job.run(
            # ... other parameters ...
            budget_milli_node_hours=1000 # Example: 1 node hour budget
            # ...
        )
        ```
*   **Bias/Variance Optimization:**
    *   **Variance Control (Overfitting):** The use of a separate validation set (handled automatically by the chronological split) allows AutoML to monitor performance on unseen data during training and select models/hyperparameters that generalize well, mitigating overfitting.
    *   **Bias Assessment (Underfitting):** By examining the final evaluation metrics on the test set (see next section), we can assess potential bias. If all error metrics (RMSE, MAE, etc.) are high across most time series, it might indicate the model is too simple or lacks the capacity to capture the underlying patterns (underfitting). AutoML aims to find a good balance by exploring complex models.
    *   The performance on the validation set during the AutoML search helps guide the selection towards models that balance bias and variance effectively for the given budget.

### ML.3.4.3.7 Machine Learning Model Evaluation

**Evaluation Process:**
Vertex AI Forecast automatically evaluates the trained model(s) on the test set portion of the data (typically the final 10% chronologically, withheld during training and validation). The evaluation metrics are computed across all time series and forecast horizons.

**Retrieving Metrics:**
These evaluation metrics can be accessed in two ways:
1.  **Google Cloud Console:** Navigate to Vertex AI -> Training -> [Your Training Job Name] -> Model tab. The UI displays comprehensive evaluation metrics and visualizations.
2.  **Vertex AI SDK:** Programmatically retrieve the evaluation results using the trained model object.

**Key Evaluation Metrics (Provided by Vertex AI Forecast):**
*   **RMSE (Root Mean Squared Error):** The primary optimization target. Measures the square root of the average squared differences between predicted and actual values. Sensitive to large errors.
*   **MAE (Mean Absolute Error):** Average absolute difference between predicted and actual values. Less sensitive to outliers than RMSE.
*   **MAPE (Mean Absolute Percentage Error):** Average percentage difference. Useful for understanding error relative to the actual values, but can be skewed by low actual values.
*   **WAPE (Weighted Absolute Percentage Error):** Similar to MAPE but weighted by the actual values, making it more stable when actuals are near zero.
*   **RÂ² (R-squared):** Coefficient of determination. Indicates the proportion of variance in the dependent variable predictable from the independent variables (features). Not always the best metric for time series.
*   **Quantile Errors (e.g., P50, P90):** Error metrics calculated at specific quantiles, useful for understanding prediction intervals and uncertainty.

**Example Evaluation Results (Illustrative - Replace with Actual Values):**
*(These values should be populated from your actual Vertex AI Training Job results)*

| Metric          | Value (Test Set) |
| :-------------- | :--------------- |
| RMSE            | 15.3             |
| MAE             | 9.8              |
| MAPE            | 35.2%            |
| WAPE            | 28.1%            |
| RÂ²              | 0.75             |
| P50 MAE         | 8.5              |
| P90 MAE         | 14.2             |

*(Include a brief interpretation, e.g., "The RMSE of 15.3 indicates an average error magnitude... The WAPE suggests an average error of about 28% weighted by volume... The model explains 75% of the variance according to RÂ².")*

**Code Snippet Example (Illustrative - Retrieving Evaluation via SDK):**
```python
from google.cloud import aiplatform

# Assuming 'model' is the trained aiplatform.Model object retrieved after training
# Example: model = aiplatform.Model('projects/PROJECT_ID/locations/REGION/models/MODEL_ID')

# List model evaluations (usually one for AutoML)
evaluations = model.list_model_evaluations()

if evaluations:
    # Get the first (typically only) evaluation
    model_evaluation = evaluations[0]

    print(f"Model Evaluation Resource Name: {model_evaluation.resource_name}")
    print(f"Metrics Dict: {model_evaluation.metrics}")

    # Access specific metrics (keys might vary slightly based on model type)
    rmse = model_evaluation.metrics.get('rmse')
    mae = model_evaluation.metrics.get('mae')
    mape = model_evaluation.metrics.get('mape')
    wape = model_evaluation.metrics.get('wape') # Or similar key
    r2 = model_evaluation.metrics.get('rSquared') # Or similar key

    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"MAPE: {mape}%") # Check if MAPE is scaled
    print(f"WAPE: {wape}%") # Check if WAPE is scaled
    print(f"R-squared: {r2}")
else:
    print("No model evaluations found for this model.")

```
This snippet shows how to programmatically access the evaluation metrics stored with the registered Vertex AI model.

---

## ğŸ—ï¸ Data Pipeline & Preprocessing

### ğŸ”— Source

- Dataset : `bigquery-public-data.chicago_taxi_trips.taxi_trips`
- Pipeline SQL dans `bigquery_queries.sql`
- Table finale : `avisia-certification-ml-yde.chicago_taxis.demand_by_hour`

### âš™ï¸ Ã‰tapes du pipeline

1. Troncature Ã  lâ€™heure (`TIMESTAMP_TRUNC`)
2. AgrÃ©gation : `COUNT(*) AS trip_count`
3. SÃ©ries complÃ¨tes via CROSS JOIN + LEFT JOIN
4. Remplissage des valeurs manquantes
5. Enrichissement temporel
6. Export possible vers GCS si besoin

---

## ğŸ¤– Model Development â€“ Vertex AI Forecast

### ğŸ“¦ Dataset

- CrÃ©ation via `aiplatform.TimeSeriesDataset.create_from_bigquery()`
- Colonnes spÃ©cifiÃ©es :
  - `time_column`: `timestamp_hour`
  - `target_column`: `trip_count`
  - `time_series_identifier_column`: `pickup_community_area`
  - Features disponibles : `hour`, `day_of_week`, `month`, `is_holiday`, etc.

### ğŸš€ EntraÃ®nement

- Job : `AutoMLForecastingTrainingJob`
- ParamÃ¨tres :
  - `forecast_horizon`: 24
  - `context_window`: 168 (1 semaine)
  - `optimization_objective`: `minimize-rmse`
  - Budget : 1h Ã  4h selon configuration
- RÃ©sultat : modÃ¨le dÃ©ployable dans Vertex AI

### ğŸ“ˆ Ã‰valuation

- Backtesting intÃ©grÃ©
- MÃ©triques :
  - RMSE, MAE, RÂ², quantiles
- Visualisation des rÃ©sultats dans `3_Forecasting_Training.ipynb`

### ML.3.4.3.6 Machine Learning Model Training and Development

Model training is performed using Vertex AI Training, specifically leveraging the AutoML Forecasting capability orchestrated via a Vertex AI Pipeline.

**Training Environment:** Vertex AI Training (Serverless)

**Key Aspects:**

*   **Data Splitting (Sampling):** Vertex AI Forecast automatically handles data splitting for time series. By default, it uses a chronological split based on the time column. The typical splits configured (visible in `config/pipeline_config.yaml` or passed to the job) are often 80% for training, 10% for validation, and 10% for testing. This ensures the model is validated and tested on data points that occur *after* the training data, preventing data leakage from the future.
    *   *Code Snippet (Illustrative - Parameters affecting splits are part of `job.run`):* The `forecast_horizon` and `context_window` parameters implicitly define how data is used. Vertex AI determines the latest possible training data point based on the horizon needed for the first test point. Specific split fractions (`training_fraction_split`, `validation_fraction_split`, `test_fraction_split`) can also be set if default behavior needs overriding.
*   **Implementation & GCP Best Practices:**
    *   **Vertex AI SDK & Pipelines:** Training is invoked programmatically using the `google-cloud-aiplatform` SDK within a KFP component, facilitating MLOps automation and reproducibility.
    *   **Serverless Training:** AutoML training jobs run on Google-managed infrastructure, eliminating the need for manual provisioning or management of training clusters.
    *   **Artifact Management:** The trained model is automatically registered in the Vertex AI Model Registry, linking it to the training job and dataset.
    *   **Monitoring:** Training progress and resource consumption can be monitored via the Google Cloud Console (Vertex AI -> Training).
    *   *Code Snippet:* The `job.run(...)` call shown in the previous section (ML.3.4.3.5) represents the core implementation step following GCP best practices for managed ML training.
*   **Evaluation Metric:** The primary metric used for optimization is **Root Mean Squared Error (RMSE)** (`optimization_objective='minimize-rmse'`).
    *   **Rationale:** RMSE was chosen because it heavily penalizes large prediction errors. In the context of taxi demand, underestimating demand significantly during peak hours (leading to large errors) could result in poor service and lost revenue, making it important to minimize these large deviations. Other metrics like MAE or MAPE are also calculated by Vertex AI and can be used for supplementary evaluation.
*   **Hyperparameter Optimization (HPO):** Vertex AI AutoML internally performs HPO. It searches through different model architectures and hyperparameters within the constraints of the allocated training budget (`budget_milli_node_hours`). The specific algorithms and search space are managed by Google.
    *   *Code Snippet (Illustrative - Budget Parameter):* The budget is specified during the `job.run` call:
        ```python
        model = job.run(
            # ... other parameters ...
            budget_milli_node_hours=1000 # Example: 1 node hour budget
            # ...
        )
        ```
*   **Bias/Variance Optimization:**
    *   **Variance Control (Overfitting):** The use of a separate validation set (handled automatically by the chronological split) allows AutoML to monitor performance on unseen data during training and select models/hyperparameters that generalize well, mitigating overfitting.
    *   **Bias Assessment (Underfitting):** By examining the final evaluation metrics on the test set (see next section), we can assess potential bias. If all error metrics (RMSE, MAE, etc.) are high across most time series, it might indicate the model is too simple or lacks the capacity to capture the underlying patterns (underfitting). AutoML aims to find a good balance by exploring complex models.
    *   The performance on the validation set during the AutoML search helps guide the selection towards models that balance bias and variance effectively for the given budget.

### ML.3.4.3.7 Machine Learning Model Evaluation

**Evaluation Process:**
Vertex AI Forecast automatically evaluates the trained model(s) on the test set portion of the data (typically the final 10% chronologically, withheld during training and validation). The evaluation metrics are computed across all time series and forecast horizons.

**Retrieving Metrics:**
These evaluation metrics can be accessed in two ways:
1.  **Google Cloud Console:** Navigate to Vertex AI -> Training -> [Your Training Job Name] -> Model tab. The UI displays comprehensive evaluation metrics and visualizations.
2.  **Vertex AI SDK:** Programmatically retrieve the evaluation results using the trained model object.

**Key Evaluation Metrics (Provided by Vertex AI Forecast):**
*   **RMSE (Root Mean Squared Error):** The primary optimization target. Measures the square root of the average squared differences between predicted and actual values. Sensitive to large errors.
*   **MAE (Mean Absolute Error):** Average absolute difference between predicted and actual values. Less sensitive to outliers than RMSE.
*   **MAPE (Mean Absolute Percentage Error):** Average percentage difference. Useful for understanding error relative to the actual values, but can be skewed by low actual values.
*   **WAPE (Weighted Absolute Percentage Error):** Similar to MAPE but weighted by the actual values, making it more stable when actuals are near zero.
*   **RÂ² (R-squared):** Coefficient of determination. Indicates the proportion of variance in the dependent variable predictable from the independent variables (features). Not always the best metric for time series.
*   **Quantile Errors (e.g., P50, P90):** Error metrics calculated at specific quantiles, useful for understanding prediction intervals and uncertainty.

**Example Evaluation Results (Illustrative - Replace with Actual Values):**
*(These values should be populated from your actual Vertex AI Training Job results)*

| Metric          | Value (Test Set) |
| :-------------- | :--------------- |
| RMSE            | 15.3             |
| MAE             | 9.8              |
| MAPE            | 35.2%            |
| WAPE            | 28.1%            |
| RÂ²              | 0.75             |
| P50 MAE         | 8.5              |
| P90 MAE         | 14.2             |

*(Include a brief interpretation, e.g., "The RMSE of 15.3 indicates an average error magnitude... The WAPE suggests an average error of about 28% weighted by volume... The model explains 75% of the variance according to RÂ².")*

**Code Snippet Example (Illustrative - Retrieving Evaluation via SDK):**
```python
from google.cloud import aiplatform

# Assuming 'model' is the trained aiplatform.Model object retrieved after training
# Example: model = aiplatform.Model('projects/PROJECT_ID/locations/REGION/models/MODEL_ID')

# List model evaluations (usually one for AutoML)
evaluations = model.list_model_evaluations()

if evaluations:
    # Get the first (typically only) evaluation
    model_evaluation = evaluations[0]

    print(f"Model Evaluation Resource Name: {model_evaluation.resource_name}")
    print(f"Metrics Dict: {model_evaluation.metrics}")

    # Access specific metrics (keys might vary slightly based on model type)
    rmse = model_evaluation.metrics.get('rmse')
    mae = model_evaluation.metrics.get('mae')
    mape = model_evaluation.metrics.get('mape')
    wape = model_evaluation.metrics.get('wape') # Or similar key
    r2 = model_evaluation.metrics.get('rSquared') # Or similar key

    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"MAPE: {mape}%") # Check if MAPE is scaled
    print(f"WAPE: {wape}%") # Check if WAPE is scaled
    print(f"R-squared: {r2}")
else:
    print("No model evaluations found for this model.")

```
This snippet shows how to programmatically access the evaluation metrics stored with the registered Vertex AI model.

---

## ğŸ¤– Deployment â€“ Batch Prediction Strategy

- Usage de `Vertex AI Batch Prediction`
- DonnÃ©es dâ€™entrÃ©e : table BigQuery `forecast_input`
- RÃ©sultats : table `forecast_output` contenant les prÃ©dictions
- Script : `4_Batch_Prediction_Demo.ipynb`
- Visualisation :
  - Graphiques temporels par zone
  - Comparaison entre zones

---

## ğŸ›¡ï¸ Security & Privacy

- DonnÃ©es publiques (pas de PII)
- Stockage GCP sÃ©curisÃ© :
  - Bucket GCS privÃ©
  - Tables BQ avec IAM restreint
- Gestion des accÃ¨s Vertex AI et BQ via service account
- IAM suivant le principe du moindre privilÃ¨ge

---

## âœ… RÃ©sultats & Impact

- PrÃ©cision de prÃ©vision RMSE ~ faible sur zones denses
- Diminution anticipÃ©e des temps dâ€™attente client
- Allocation optimale de la flotte de taxis
- Pipeline industrialisable et reproductible

---

## ğŸ“Œ Architecture RÃ©sumÃ©e

BigQuery (raw) â”‚ â”œâ”€â”€> SQL (agrÃ©gation horaire + FE) â”‚ â†“ BQ (demand_by_hour) â”‚ â””â”€â”€> Vertex AI Forecast â”œâ”€â”€> Training Job â”œâ”€â”€> Model â””â”€â”€> Batch Prediction â†“ BQ Output + Viz
---

## ğŸ“… Prochaines Ã©tapes

- IntÃ©gration des donnÃ©es mÃ©tÃ©o
- Utilisation de Looker Studio pour dashboard prÃ©dictif
- DÃ©ploiement du pipeline KFP complet
- Enrichissement avec les donnÃ©es en temps rÃ©el (Realtime Forecast)

---

## ğŸ“‚ RÃ©fÃ©rences & Artifacts

| Ã‰lÃ©ment | Chemin |
|--------|--------|
| DonnÃ©es BQ | `chicago_taxis.demand_by_hour` |
| Script prÃ©traitement | `src/data_preprocessing/bigquery_queries.sql` |
| Notebook entraÃ®nement | `notebooks/3_Forecasting_Training.ipynb`