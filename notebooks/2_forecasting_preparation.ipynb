{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from src.data_processing import load_config, load_data, preprocess_data, sample_data\n",
    "\n",
    "# Configuration visuelle\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Charger la configuration\n",
    "config = load_config(\"config/config.yaml\")\n",
    "print(\"Configuration charg√©e avec succ√®s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Cellule 2 ‚Äî Chargement du dataset complet depuis BigQuery\n",
    "python\n",
    "Copier\n",
    "Modifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_gbq import read_gbq\n",
    "\n",
    "# R√©cup√©ration du project_id depuis la configuration\n",
    "project_id = config.get(\"project_id\", \"avisia-certification-ml-yde\")\n",
    "\n",
    "# Requ√™te SQL pour charger TOUT le dataset (attention : tr√®s volumineux >187M lignes)\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  trip_start_timestamp,\n",
    "  pickup_community_area\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "WHERE pickup_community_area IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"Chargement des donn√©es depuis BigQuery... (peut prendre plusieurs minutes)\")\n",
    "\n",
    "# Chargement via pandas-gbq\n",
    "df_raw = read_gbq(query, project_id=project_id)\n",
    "\n",
    "print(f\"‚úÖ Dataset charg√© avec succ√®s. Nombre de lignes : {len(df_raw):,}\")\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚è∞ Cellule 3 ‚Äî Agr√©gation par heure et zone (trip_count par timestamp_hour √ó pickup_community_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir les timestamps au format horaire (arrondi √† l'heure)\n",
    "df_raw[\"timestamp_hour\"] = pd.to_datetime(df_raw[\"trip_start_timestamp\"]).dt.floor(\"H\")\n",
    "\n",
    "# Agr√©gation : nombre de courses par heure et par pickup_community_area\n",
    "df_demand = (\n",
    "    df_raw\n",
    "    .groupby([\"timestamp_hour\", \"pickup_community_area\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"trip_count\")\n",
    "    .sort_values([\"timestamp_hour\", \"pickup_community_area\"])\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Donn√©es agr√©g√©es : {len(df_demand):,} lignes.\")\n",
    "df_demand.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß© Cellule 4 ‚Äî Compl√©tion des s√©ries temporelles (remplir les heures sans donn√©es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Cr√©er l'ensemble des heures disponibles dans le dataset (par pas de 1 heure)\n",
    "min_time = df_demand[\"timestamp_hour\"].min()\n",
    "max_time = df_demand[\"timestamp_hour\"].max()\n",
    "all_hours = pd.date_range(start=min_time, end=max_time, freq=\"H\")\n",
    "\n",
    "# Identifier toutes les zones uniques\n",
    "all_zones = df_demand[\"pickup_community_area\"].dropna().unique()\n",
    "all_zones = sorted(all_zones)\n",
    "\n",
    "# Cr√©er le produit cart√©sien : toutes les combinaisons heure √ó zone\n",
    "complete_index = pd.MultiIndex.from_product(\n",
    "    [all_hours, all_zones],\n",
    "    names=[\"timestamp_hour\", \"pickup_community_area\"]\n",
    ")\n",
    "\n",
    "# Cr√©er un DataFrame complet\n",
    "df_complete = pd.DataFrame(index=complete_index).reset_index()\n",
    "\n",
    "# Fusionner avec les donn√©es observ√©es\n",
    "df_demand_complete = pd.merge(\n",
    "    df_complete,\n",
    "    df_demand,\n",
    "    on=[\"timestamp_hour\", \"pickup_community_area\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Remplacer les valeurs manquantes (heures sans courses) par 0\n",
    "df_demand_complete[\"trip_count\"] = df_demand_complete[\"trip_count\"].fillna(0).astype(int)\n",
    "\n",
    "print(f\"‚úÖ S√©ries temporelles compl√©t√©es : {len(df_demand_complete):,} lignes.\")\n",
    "df_demand_complete.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† Cellule 5 ‚Äî Ajout des features temporelles (hour, day, month, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Extraire les features temporelles classiques\n",
    "df_demand_complete[\"hour\"] = df_demand_complete[\"timestamp_hour\"].dt.hour\n",
    "df_demand_complete[\"day_of_week\"] = df_demand_complete[\"timestamp_hour\"].dt.dayofweek  # Lundi = 0\n",
    "df_demand_complete[\"month\"] = df_demand_complete[\"timestamp_hour\"].dt.month\n",
    "df_demand_complete[\"day_of_year\"] = df_demand_complete[\"timestamp_hour\"].dt.dayofyear\n",
    "df_demand_complete[\"week_of_year\"] = df_demand_complete[\"timestamp_hour\"].dt.isocalendar().week.astype(int)\n",
    "df_demand_complete[\"year\"] = df_demand_complete[\"timestamp_hour\"].dt.year\n",
    "df_demand_complete[\"is_weekend\"] = df_demand_complete[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Optionnel : encodage cyclique (utile pour XGBoost, moins pour AutoML Forecasting qui encode en interne)\n",
    "df_demand_complete[\"hour_sin\"] = np.sin(2 * np.pi * df_demand_complete[\"hour\"] / 24)\n",
    "df_demand_complete[\"hour_cos\"] = np.cos(2 * np.pi * df_demand_complete[\"hour\"] / 24)\n",
    "\n",
    "print(\"‚úÖ Features temporelles ajout√©es.\")\n",
    "df_demand_complete[[\"timestamp_hour\", \"hour\", \"day_of_week\", \"month\", \"is_weekend\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Cellule 6 ‚Äî Export des donn√©es finales vers BigQuery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialisation du client BigQuery\n",
    "client = bigquery.Client(project=\"avisia-certification-ml-yde\")\n",
    "\n",
    "# D√©finir la destination\n",
    "table_id = \"avisia-certification-ml-yde.chicago_taxis.demand_by_hour\"\n",
    "\n",
    "# Option : supprimer les colonnes inutiles ou sp√©cifiques √† XGBoost\n",
    "columns_to_keep = [\n",
    "    \"timestamp_hour\", \"pickup_community_area\", \"trip_count\",\n",
    "    \"hour\", \"day_of_week\", \"month\", \"year\", \"day_of_year\", \"week_of_year\", \"is_weekend\"\n",
    "]\n",
    "\n",
    "# On s√©lectionne uniquement les colonnes utiles pour Vertex AI Forecast\n",
    "df_to_export = df_demand_complete[columns_to_keep]\n",
    "\n",
    "# √âcriture dans BigQuery\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(\n",
    "    df_to_export, table_id, job_config=job_config\n",
    ")\n",
    "\n",
    "job.result()  # Attendre la fin du job\n",
    "\n",
    "print(f\"‚úÖ Table export√©e vers BigQuery : {table_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
