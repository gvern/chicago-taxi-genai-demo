{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13345e1e",
   "metadata": {},
   "source": [
    "# 3. Prédiction Batch et Visualisation - Chicago Taxi Demand\n",
    "\n",
    "Ce notebook couvre la génération de prévisions batch pour la demande de taxis à Chicago et leur visualisation. Nous allons :\n",
    "- Préparer les données d'entrée pour la prédiction batch\n",
    "- Charger un modèle entraîné depuis Vertex AI Model Registry\n",
    "- Générer des prédictions batch pour les périodes futures\n",
    "- Analyser et visualiser les résultats de prévision\n",
    "- Explorer les patterns spatiaux et temporels des prévisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77ec81",
   "metadata": {},
   "source": [
    "## 1. Configuration et Initialisation\n",
    "\n",
    "Importons les bibliothèques nécessaires et initialisons l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d45c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothèques standards\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import holidays\n",
    "\n",
    "# Google Cloud & Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Visualisations avancées\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration visuelle\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034742b3",
   "metadata": {},
   "source": [
    "## 2. Configuration du Projet GCP\n",
    "\n",
    "Définissons les identifiants du projet et initialisons Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavevernay/Desktop/Projets/Pro/Avisia/chicago-taxi-genai-demo/venv/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environnement initialisé avec succès pour le projet avisia-certification-ml-yde\n"
     ]
    }
   ],
   "source": [
    "# Configuration du projet GCP\n",
    "PROJECT_ID = \"avisia-certification-ml-yde\"  # Remplacez par votre Project ID\n",
    "REGION = \"europe-west1\"\n",
    "BQ_DATASET = \"chicago_taxis\"\n",
    "\n",
    "# Tables BigQuery pour l'entrée et la sortie des prédictions\n",
    "BQ_INPUT = f\"bq://{PROJECT_ID}.{BQ_DATASET}.forecast_input\"   # table contenant les timestamps futurs\n",
    "BQ_OUTPUT = f\"bq://{PROJECT_ID}.{BQ_DATASET}\"  # table où seront stockées les prédictions\n",
    "\n",
    "# Initialisation de Vertex AI\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# Initialisation du client BigQuery\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "print(f\"✅ Environnement initialisé avec succès pour le projet {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030c532",
   "metadata": {},
   "source": [
    "## 3. Chargement de la Configuration\n",
    "\n",
    "Chargeons les paramètres de configuration depuis le fichier YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b54025c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration chargée avec succès.\n",
      "Horizon de prévision configuré: 24 heures\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier de configuration\n",
    "try:\n",
    "    with open(\"../config/pipeline_config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"✅ Configuration chargée avec succès.\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        with open(\"config/pipeline_config.yaml\", \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(\"✅ Configuration chargée avec succès.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"⚠️ Fichier de configuration introuvable. Utilisation des valeurs par défaut.\")\n",
    "        config = {\n",
    "            \"forecasting\": {\n",
    "                \"time_column\": \"timestamp_hour\",\n",
    "                \"target_column\": \"trip_count\",\n",
    "                \"context_column\": \"pickup_community_area\",\n",
    "                \"forecast_horizon\": 24\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Extraction des paramètres de configuration\n",
    "forecast_config = config.get(\"forecasting\", {})\n",
    "vertex_config = config.get(\"vertex_ai_forecast\", {})\n",
    "\n",
    "# Paramètres clés pour le forecasting\n",
    "time_column = forecast_config.get(\"time_column\", \"timestamp_hour\")\n",
    "target_column = forecast_config.get(\"target_column\", \"trip_count\")\n",
    "context_column = forecast_config.get(\"context_column\", \"pickup_community_area\")\n",
    "forecast_horizon = forecast_config.get(\"forecast_horizon\", 24)\n",
    "\n",
    "print(f\"Horizon de prévision configuré: {forecast_horizon} heures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96348bc9",
   "metadata": {},
   "source": [
    "## 4. Génération des Données d'Entrée pour la Prédiction\n",
    "\n",
    "Créons les données d'entrée pour la prédiction batch avec des timestamps futurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab57d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chicago_holidays(start_date, end_date):\n",
    "    \"\"\"Renvoie les jours fériés américains (Chicago) dans l'intervalle donné.\"\"\"\n",
    "    us_holidays = holidays.US(years=range(start_date.year, end_date.year + 1))\n",
    "    return set(us_holidays.keys())\n",
    "\n",
    "def get_unique_zones():\n",
    "    \"\"\"Récupère les pickup_community_area uniques depuis la table de training.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT pickup_community_area\n",
    "    FROM `{PROJECT_ID}.{BQ_DATASET}.demand_by_hour`\n",
    "    ORDER BY pickup_community_area\n",
    "    \"\"\"\n",
    "    return client.query(query).to_dataframe()\n",
    "\n",
    "def get_future_timestamps(n_hours=None):\n",
    "    \"\"\"Génère une liste d'horodatages horaires futurs.\"\"\"\n",
    "    if n_hours is None:\n",
    "        n_hours = forecast_horizon\n",
    "    \n",
    "    # Commencer à partir de la prochaine heure arrondie\n",
    "    now = datetime.now()\n",
    "    start = (now.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1))\n",
    "    \n",
    "    # Générer la séquence d'horodatages\n",
    "    return [start + timedelta(hours=i) for i in range(n_hours)]\n",
    "\n",
    "def generate_forecast_input():\n",
    "    \"\"\"Génère le DataFrame d'entrée pour la prédiction batch.\"\"\"\n",
    "    # Récupérer les zones\n",
    "    zones_df = get_unique_zones()\n",
    "    \n",
    "    # Générer le cartésien zones × timestamps\n",
    "    timestamps = get_future_timestamps()\n",
    "    start, end = timestamps[0], timestamps[-1]\n",
    "    holidays_set = get_chicago_holidays(start, end)\n",
    "    \n",
    "    rows = []\n",
    "    for zone in zones_df[\"pickup_community_area\"]:\n",
    "        for ts in timestamps:\n",
    "            rows.append({\n",
    "                \"pickup_community_area\": zone,\n",
    "                \"timestamp_hour\": ts,\n",
    "                \"hour\": ts.hour,\n",
    "                \"day_of_week\": ts.weekday(),\n",
    "                \"month\": ts.month,\n",
    "                \"day_of_year\": ts.timetuple().tm_yday,\n",
    "                \"is_weekend\": 1 if ts.weekday() >= 5 else 0,\n",
    "                \"is_holiday\": 1 if ts.date() in holidays_set else 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def write_to_bigquery(df):\n",
    "    \"\"\"Écrit le dataframe dans BigQuery avec schéma défini.\"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{BQ_DATASET}.forecast_input\"\n",
    "    \n",
    "    # Configuration du job\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\"\n",
    "    )\n",
    "    \n",
    "    # Chargement des données\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    job.result()  # Attendre la fin du job\n",
    "    \n",
    "    return table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca45009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des données d'entrée pour la prédiction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavevernay/Desktop/Projets/Pro/Avisia/chicago-taxi-genai-demo/venv/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données générées: 1848 lignes, 8 colonnes\n",
      "\n",
      "Aperçu des données d'entrée:\n",
      "\n",
      "Export des données vers BigQuery...\n",
      "✅ Données exportées vers la table: avisia-certification-ml-yde.chicago_taxis.forecast_input\n"
     ]
    }
   ],
   "source": [
    "# Génération des données d'entrée pour la prédiction\n",
    "print(\"Génération des données d'entrée pour la prédiction...\")\n",
    "df_input = generate_forecast_input()\n",
    "print(f\"✅ Données générées: {df_input.shape[0]} lignes, {df_input.shape[1]} colonnes\")\n",
    "\n",
    "# Aperçu des données générées\n",
    "print(\"\\nAperçu des données d'entrée:\")\n",
    "df_input.head()\n",
    "\n",
    "# Export vers BigQuery\n",
    "try:\n",
    "    print(\"\\nExport des données vers BigQuery...\")\n",
    "    table_id = write_to_bigquery(df_input)\n",
    "    print(f\"✅ Données exportées vers la table: {table_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de l'export vers BigQuery: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cd64d",
   "metadata": {},
   "source": [
    "## 5. Chargement du Modèle Entraîné\n",
    "\n",
    "Chargeons le modèle de prévision entraîné depuis Vertex AI Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34bd8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche du modèle le plus récent avec le préfixe: 'chicago_taxi_forecast_model'\n",
      "✅ Modèle trouvé: chicago_taxi_forecast_model_20250415_1127 (Resource Name: projects/807699310940/locations/europe-west1/models/988694049835712512, créé le 2025-04-15 09:27:35.570357+00:00)\n"
     ]
    }
   ],
   "source": [
    "# Récupération du modèle le plus récent\n",
    "# Utiliser le préfixe défini dans la configuration pour la recherche\n",
    "model_prefix = config.get(\"model_registry\", {}).get(\"model_display_name_prefix\", \"chicago_taxi_forecast_model\")\n",
    "print(f\"Recherche du modèle le plus récent avec le préfixe: '{model_prefix}'\")\n",
    "\n",
    "try:\n",
    "    # Rechercher les modèles dont le nom commence par le préfixe\n",
    "    # Note: L'API ne supporte pas directement 'LIKE' ou 'STARTS_WITH' dans le filtre standard.\n",
    "    # On liste donc tous les modèles (ou un sous-ensemble si possible) et on filtre côté client,\n",
    "    # ou on utilise un nom exact si la pipeline l'enregistre de manière prédictible.\n",
    "    # Alternative: Utiliser un nom exact si connu ou le récupérer depuis la sortie de la pipeline HPT.\n",
    "\n",
    "    # Stratégie 1: Lister avec un filtre plus large et trier/filtrer ensuite (peut être lent si bcp de modèles)\n",
    "    # models = aiplatform.Model.list(order_by=\"create_time desc\")\n",
    "    # matching_models = [m for m in models if m.display_name.startswith(model_prefix)]\n",
    "\n",
    "    # Stratégie 2: Essayer de récupérer le modèle via une sortie de pipeline (plus robuste si disponible)\n",
    "    # Si l'URI du modèle est passé d'une étape précédente (ex: sortie de HPT job), l'utiliser directement:\n",
    "    # model_resource_name = \"URI_OU_NOM_COMPLET_DU_MODELE_DE_LA_PIPELINE\"\n",
    "    # model = aiplatform.Model(model_name=model_resource_name)\n",
    "    # print(f\"✅ Modèle chargé directement via resource name: {model.display_name}\")\n",
    "\n",
    "    # Stratégie 3: Utiliser list avec un nom exact si la convention de nommage est fixe.\n",
    "    # Supposons que le dernier modèle HPT enregistré ait un nom prédictible ou soit taggué 'latest'.\n",
    "    # Pour cet exemple, on va chercher les modèles commençant par le préfixe et prendre le plus récent.\n",
    "    \n",
    "    all_models = aiplatform.Model.list(order_by=\"create_time desc\")\n",
    "    models = [m for m in all_models if m.display_name.startswith(model_prefix)]\n",
    "\n",
    "    if models:\n",
    "        model = models[0]  # Prendre le plus récent correspondant au préfixe\n",
    "        print(f\"✅ Modèle trouvé: {model.display_name} (Resource Name: {model.resource_name}, créé le {model.create_time})\")\n",
    "        # Stocker le nom de ressource pour le job batch (plus fiable que display_name)\n",
    "        model_resource_name = model.resource_name\n",
    "    else:\n",
    "        # Si aucun modèle n'est trouvé avec le préfixe\n",
    "        raise ValueError(f\"Aucun modèle trouvé avec le préfixe '{model_prefix}'. Vérifiez le nom dans config/pipeline_config.yaml et si la pipeline d'entraînement a bien enregistré un modèle.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors du chargement du modèle: {e}\")\n",
    "    # Réinitialiser la variable modèle en cas d'erreur\n",
    "    model = None\n",
    "    model_resource_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d178676",
   "metadata": {},
   "source": [
    "## 6. Lancement de la Prédiction Batch\n",
    "\n",
    "Utilisons le modèle pour générer des prédictions sur les données futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a18ee272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Lancement du job de prédiction batch...\n",
      "Creating BatchPredictionJob\n",
      "❌ Erreur lors de la prédiction batch: 400 Table name is not allowed in Bigquery output uri.\n"
     ]
    }
   ],
   "source": [
    "# Nom du job de prédiction batch\n",
    "batch_job_name = f\"batch_pred_taxi_demand_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "try:\n",
    "    # Lancement du job de prédiction batch\n",
    "    print(f\"⏳ Lancement du job de prédiction batch...\")\n",
    "    batch_job = model.batch_predict(\n",
    "        job_display_name=batch_job_name,\n",
    "        instances_format=\"bigquery\",\n",
    "        predictions_format=\"bigquery\",\n",
    "        bigquery_source=BQ_INPUT,\n",
    "        bigquery_destination_prefix=BQ_OUTPUT,\n",
    "        sync=True,  # Mode synchrone: attend la fin du job\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Prédictions générées avec succès!\")\n",
    "    print(f\"Les résultats sont stockés dans: {BQ_OUTPUT}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la prédiction batch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ca02d",
   "metadata": {},
   "source": [
    "## 7. Récupération et Analyse des Résultats\n",
    "\n",
    "Récupérons les résultats des prédictions de BigQuery et analysons-les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37a09adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Erreur lors de la récupération des prédictions: 400 Invalid project ID 'avisia-certification-ml-yde.chicago_taxis'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.; reason: invalid, location: avisia-certification-ml-yde.chicago_taxis.forecast_output.predictions, message: Invalid project ID 'avisia-certification-ml-yde.chicago_taxis'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.\n",
      "\n",
      "Location: US\n",
      "Job ID: 4819e221-0cdf-470c-b316-524c2c09218d\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requête pour récupérer les prédictions\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  instance.pickup_community_area,\n",
    "  instance.timestamp_hour,\n",
    "  instance.hour,\n",
    "  instance.day_of_week,\n",
    "  instance.is_weekend,\n",
    "  prediction.value[OFFSET(0)] AS predicted_trip_count\n",
    "FROM `{PROJECT_ID}.{BQ_DATASET}.forecast_output.predictions`\n",
    "ORDER BY timestamp_hour, pickup_community_area\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Exécution de la requête\n",
    "    df_pred = client.query(query).to_dataframe()\n",
    "    \n",
    "    # Conversion des types\n",
    "    df_pred['timestamp_hour'] = pd.to_datetime(df_pred['timestamp_hour'])\n",
    "    df_pred['predicted_trip_count'] = df_pred['predicted_trip_count'].astype(float)\n",
    "    \n",
    "    print(f\"✅ Prédictions récupérées: {df_pred.shape[0]} lignes\")\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    print(\"\\nStatistiques des prédictions:\")\n",
    "    print(df_pred['predicted_trip_count'].describe())\n",
    "    \n",
    "    # Aperçu des prédictions\n",
    "    print(\"\\nAperçu des prédictions:\")\n",
    "    df_pred.head()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la récupération des prédictions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c505d99",
   "metadata": {},
   "source": [
    "## 8. Visualisation des Prévisions\n",
    "\n",
    "Visualisons les prévisions pour les zones les plus actives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e480aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de la visualisation des prévisions: name 'df_pred' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavevernay/Desktop/Projets/Pro/Avisia/chicago-taxi-genai-demo/venv/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Identifier les zones les plus actives\n",
    "top_zones_query = f\"\"\"\n",
    "SELECT pickup_community_area, SUM(trip_count) as total_trips\n",
    "FROM `{PROJECT_ID}.{BQ_DATASET}.demand_by_hour`\n",
    "GROUP BY pickup_community_area\n",
    "ORDER BY total_trips DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Récupérer les top zones\n",
    "    top_zones_df = client.query(top_zones_query).to_dataframe()\n",
    "    top_zones = top_zones_df['pickup_community_area'].tolist()\n",
    "    \n",
    "    # Filtrer les prédictions pour ces zones\n",
    "    df_filtered = df_pred[df_pred['pickup_community_area'].isin(top_zones)]\n",
    "    \n",
    "    # Visualisation avec Matplotlib/Seaborn\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.lineplot(\n",
    "        data=df_filtered, \n",
    "        x='timestamp_hour', \n",
    "        y='predicted_trip_count', \n",
    "        hue='pickup_community_area',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Prévision du nombre de courses par heure (5 zones principales)', fontsize=16)\n",
    "    plt.xlabel('Heure de prévision', fontsize=14)\n",
    "    plt.ylabel('Nombre de courses prévues', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualisation interactive avec Plotly\n",
    "    fig = px.line(\n",
    "        df_filtered, \n",
    "        x='timestamp_hour', \n",
    "        y='predicted_trip_count', \n",
    "        color='pickup_community_area',\n",
    "        title='Prévision du nombre de courses par heure (interactive)',\n",
    "        labels={\n",
    "            'timestamp_hour': 'Heure de prévision',\n",
    "            'predicted_trip_count': 'Nombre de courses prévues',\n",
    "            'pickup_community_area': 'Zone de prise en charge'\n",
    "        }\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Heure de prévision',\n",
    "        yaxis_title='Nombre de courses prévues',\n",
    "        legend_title='Zone',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de la visualisation des prévisions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10985d",
   "metadata": {},
   "source": [
    "## 9. Analyse des Patterns Horaires\n",
    "\n",
    "Analysons les patterns horaires des prévisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd75031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de l'analyse des patterns horaires: name 'df_pred' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Analyse par heure de la journée\n",
    "try:\n",
    "    # Agréger les prévisions par heure\n",
    "    hourly_pred = df_pred.groupby('hour')['predicted_trip_count'].mean().reset_index()\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(x='hour', y='predicted_trip_count', data=hourly_pred, palette='viridis')\n",
    "    plt.title('Nombre Moyen de Courses Prévues par Heure de la Journée', fontsize=16)\n",
    "    plt.xlabel('Heure (0-23)', fontsize=14)\n",
    "    plt.ylabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.xticks(range(24))\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse par jour de la semaine et heure\n",
    "    day_hour_pred = df_pred.groupby(['day_of_week', 'hour'])['predicted_trip_count'].mean().reset_index()\n",
    "    day_hour_pivot = day_hour_pred.pivot(index='hour', columns='day_of_week', values='predicted_trip_count')\n",
    "    \n",
    "    # Renommer les colonnes pour plus de clarté\n",
    "    day_names = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "    day_hour_pivot.columns = [day_names[int(day)] for day in day_hour_pivot.columns]\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(\n",
    "        day_hour_pivot, \n",
    "        cmap='viridis', \n",
    "        annot=True, \n",
    "        fmt='.1f',\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    plt.title('Nombre Moyen de Courses Prévues par Jour et Heure', fontsize=16)\n",
    "    plt.xlabel('Jour de la Semaine', fontsize=14)\n",
    "    plt.ylabel('Heure de la Journée', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de l'analyse des patterns horaires: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d9f09",
   "metadata": {},
   "source": [
    "## 10. Analyse Spatiale des Prévisions\n",
    "\n",
    "Analysons la distribution spatiale des prévisions par zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbf8273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de l'analyse spatiale: name 'df_pred' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Agrégation par zone\n",
    "try:\n",
    "    zone_pred = df_pred.groupby('pickup_community_area')['predicted_trip_count'].mean().reset_index()\n",
    "    zone_pred = zone_pred.sort_values('predicted_trip_count', ascending=False)\n",
    "    \n",
    "    # Top 15 zones les plus actives\n",
    "    top_15_zones = zone_pred.head(15)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.barplot(\n",
    "        x='pickup_community_area', \n",
    "        y='predicted_trip_count', \n",
    "        data=top_15_zones,\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('15 Zones avec le Plus Grand Nombre Moyen de Courses Prévues', fontsize=16)\n",
    "    plt.xlabel('Zone (pickup_community_area)', fontsize=14)\n",
    "    plt.ylabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Distribution des prévisions à travers toutes les zones\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.histplot(zone_pred['predicted_trip_count'], bins=30, kde=True)\n",
    "    plt.title('Distribution du Nombre Moyen de Courses Prévues par Zone', fontsize=16)\n",
    "    plt.xlabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.ylabel('Nombre de Zones', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de l'analyse spatiale: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaeb88a",
   "metadata": {},
   "source": [
    "## 11. Comparaison Weekend vs. Jours de Semaine\n",
    "\n",
    "Comparons les prévisions pour les weekends et les jours de semaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a45a3373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de la comparaison weekend vs. semaine: name 'df_pred' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Agrégation par heure et weekend/semaine\n",
    "    weekend_hourly = df_pred.groupby(['hour', 'is_weekend'])['predicted_trip_count'].mean().reset_index()\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.lineplot(\n",
    "        data=weekend_hourly, \n",
    "        x='hour', \n",
    "        y='predicted_trip_count', \n",
    "        hue='is_weekend',\n",
    "        palette=['#1f77b4', '#ff7f0e'],\n",
    "        markers=['o', 's'],\n",
    "        style='is_weekend',\n",
    "        linewidth=2.5\n",
    "    )\n",
    "    plt.title('Nombre Moyen de Courses Prévues par Heure: Weekend vs. Semaine', fontsize=16)\n",
    "    plt.xlabel('Heure de la Journée', fontsize=14)\n",
    "    plt.ylabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.xticks(range(24))\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(labels=['Semaine', 'Weekend'], title='Période')\n",
    "    plt.show()\n",
    "    \n",
    "    # Comparaison pour les zones principales\n",
    "    if 'top_zones' in locals():\n",
    "        top_zone_weekend = df_pred[df_pred['pickup_community_area'].isin(top_zones[:3])]\n",
    "        \n",
    "        g = sns.FacetGrid(\n",
    "            top_zone_weekend, \n",
    "            col='pickup_community_area', \n",
    "            hue='is_weekend',\n",
    "            col_wrap=1, \n",
    "            height=4, \n",
    "            aspect=3,\n",
    "            sharex=True\n",
    "        )\n",
    "        g.map(sns.lineplot, 'hour', 'predicted_trip_count')\n",
    "        g.add_legend(labels=['Semaine', 'Weekend'])\n",
    "        g.set_axis_labels('Heure de la Journée', 'Nombre de Courses Prévues')\n",
    "        g.set_titles('Zone {col_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de la comparaison weekend vs. semaine: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86ef97",
   "metadata": {},
   "source": [
    "## 12. Conclusion et Prochaines Étapes\n",
    "\n",
    "### Résumé des Analyses\n",
    "- Nous avons généré des prévisions de demande de taxis pour les périodes futures\n",
    "- Les visualisations temporelles montrent des patterns clairs par heure et par jour\n",
    "- L'analyse spatiale identifie les zones avec la plus forte demande prévue\n",
    "- La comparaison weekend vs. semaine révèle des différences significatives dans les patterns de demande\n",
    "\n",
    "### Insights Métier\n",
    "- Les heures de pointe pour la demande de taxis sont principalement le matin et le soir en semaine\n",
    "- Le weekend montre une demande plus élevée en soirée et la nuit\n",
    "- Certaines zones ont une demande significativement plus élevée que d'autres\n",
    "- Ces informations peuvent aider à optimiser l'allocation des taxis dans le temps et l'espace\n",
    "\n",
    "### Prochaines Étapes\n",
    "- Intégrer des données météorologiques et d'événements pour améliorer les prévisions\n",
    "- Développer un tableau de bord en temps réel pour suivre les prévisions\n",
    "- Explorer des stratégies d'optimisation de la flotte basées sur ces prévisions\n",
    "- Évaluer et raffiner régulièrement le modèle avec de nouvelles données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
