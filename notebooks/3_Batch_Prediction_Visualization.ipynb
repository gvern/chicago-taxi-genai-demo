{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13345e1e",
   "metadata": {},
   "source": [
    "# 3. Prédiction Batch et Visualisation - Chicago Taxi Demand\n",
    "\n",
    "Ce notebook couvre la génération de prévisions batch pour la demande de taxis à Chicago et leur visualisation. Nous allons :\n",
    "- Préparer les données d'entrée pour la prédiction batch\n",
    "- Charger un modèle entraîné depuis Vertex AI Model Registry\n",
    "- Générer des prédictions batch pour les périodes futures\n",
    "- Analyser et visualiser les résultats de prévision\n",
    "- Explorer les patterns spatiaux et temporels des prévisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77ec81",
   "metadata": {},
   "source": [
    "## 1. Configuration et Initialisation\n",
    "\n",
    "Importons les bibliothèques nécessaires et initialisons l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d45c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothèques standards\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import holidays\n",
    "\n",
    "# Google Cloud & Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Visualisations avancées\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration visuelle\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034742b3",
   "metadata": {},
   "source": [
    "## 2. Configuration du Projet GCP\n",
    "\n",
    "Définissons les identifiants du projet et initialisons Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "409bb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavevernay/Desktop/Projets/Pro/Avisia/chicago-taxi-genai-demo/venv/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset créé ou déjà existant : avisia-certification-ml-yde.chicago_taxis (location=EU)\n",
      "✅ Environnement initialisé avec succès pour le projet avisia-certification-ml-yde\n"
     ]
    }
   ],
   "source": [
    "# Configuration du projet GCP\n",
    "PROJECT_ID = \"avisia-certification-ml-yde\"  # Remplacez par votre Project ID\n",
    "REGION = \"europe-west1\"\n",
    "BQ_DATASET = \"chicago_taxis\"\n",
    "LOCATION=\"EU\"\n",
    "\n",
    "# Tables BigQuery pour l'entrée et la sortie des prédictions\n",
    "BQ_INPUT = f\"bq://{PROJECT_ID}.{BQ_DATASET}.forecast_input\"   # table contenant les timestamps futurs\n",
    "BQ_OUTPUT = f\"{PROJECT_ID}.{BQ_DATASET}\"  # table où seront stockées les prédictions\n",
    "\n",
    "# Initialisation de Vertex AI\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# Initialisation du client BigQuery\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "# Créer le dataset s'il n'existe pas\n",
    "dataset_id = f\"{PROJECT_ID}.{BQ_DATASET}\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = LOCATION\n",
    "\n",
    "try:\n",
    "    dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"✅ Dataset créé ou déjà existant : {dataset_id} (location={LOCATION})\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la création du dataset : {e}\")\n",
    "\n",
    "print(f\"✅ Environnement initialisé avec succès pour le projet {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030c532",
   "metadata": {},
   "source": [
    "## 3. Chargement de la Configuration\n",
    "\n",
    "Chargeons les paramètres de configuration depuis le fichier YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b54025c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration chargée avec succès.\n",
      "Horizon de prévision configuré: 24 heures\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier de configuration\n",
    "try:\n",
    "    with open(\"../config/pipeline_config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"✅ Configuration chargée avec succès.\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        with open(\"config/pipeline_config.yaml\", \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(\"✅ Configuration chargée avec succès.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"⚠️ Fichier de configuration introuvable. Utilisation des valeurs par défaut.\")\n",
    "        config = {\n",
    "            \"forecasting\": {\n",
    "                \"time_column\": \"timestamp_hour\",\n",
    "                \"target_column\": \"trip_count\",\n",
    "                \"context_column\": \"pickup_community_area\",\n",
    "                \"forecast_horizon\": 24\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Extraction des paramètres de configuration\n",
    "forecast_config = config.get(\"forecasting\", {})\n",
    "vertex_config = config.get(\"vertex_ai_forecast\", {})\n",
    "\n",
    "# Paramètres clés pour le forecasting\n",
    "time_column = forecast_config.get(\"time_column\", \"timestamp_hour\")\n",
    "target_column = forecast_config.get(\"target_column\", \"trip_count\")\n",
    "context_column = forecast_config.get(\"context_column\", \"pickup_community_area\")\n",
    "forecast_horizon = forecast_config.get(\"forecast_horizon\", 24)\n",
    "\n",
    "print(f\"Horizon de prévision configuré: {forecast_horizon} heures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96348bc9",
   "metadata": {},
   "source": [
    "## 4. Génération des Données d'Entrée pour la Prédiction\n",
    "\n",
    "Créons les données d'entrée pour la prédiction batch avec des timestamps futurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab57d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chicago_holidays(start_date, end_date):\n",
    "    \"\"\"Renvoie les jours fériés américains (Chicago) dans l'intervalle donné.\"\"\"\n",
    "    us_holidays = holidays.US(years=range(start_date.year, end_date.year + 1))\n",
    "    return set(us_holidays.keys())\n",
    "\n",
    "def get_unique_zones():\n",
    "    \"\"\"Récupère les pickup_community_area uniques depuis la table de training.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT pickup_community_area\n",
    "    FROM `{PROJECT_ID}.{BQ_DATASET}.demand_by_hour`\n",
    "    ORDER BY pickup_community_area\n",
    "    \"\"\"\n",
    "    return client.query(query).to_dataframe()\n",
    "\n",
    "def get_future_timestamps(n_hours=None):\n",
    "    \"\"\"Génère une liste d'horodatages horaires futurs.\"\"\"\n",
    "    if n_hours is None:\n",
    "        n_hours = forecast_horizon\n",
    "    \n",
    "    # Commencer à partir de la prochaine heure arrondie\n",
    "    now = datetime.now()\n",
    "    start = (now.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1))\n",
    "    \n",
    "    # Générer la séquence d'horodatages\n",
    "    return [start + timedelta(hours=i) for i in range(n_hours)]\n",
    "\n",
    "def generate_forecast_input():\n",
    "    \"\"\"Génère le DataFrame d'entrée pour la prédiction batch.\"\"\"\n",
    "    # Récupérer les zones\n",
    "    zones_df = get_unique_zones()\n",
    "    \n",
    "    # Générer le cartésien zones × timestamps\n",
    "    timestamps = get_future_timestamps()\n",
    "    start, end = timestamps[0], timestamps[-1]\n",
    "    holidays_set = get_chicago_holidays(start, end)\n",
    "    \n",
    "    rows = []\n",
    "    for zone in zones_df[\"pickup_community_area\"]:\n",
    "        for ts in timestamps:\n",
    "            rows.append({\n",
    "                \"pickup_community_area\": zone,\n",
    "                \"timestamp_hour\": ts,\n",
    "                \"hour\": ts.hour,\n",
    "                \"day_of_week\": ts.weekday(),\n",
    "                \"month\": ts.month,\n",
    "                \"day_of_year\": ts.timetuple().tm_yday,\n",
    "                \"is_weekend\": 1 if ts.weekday() >= 5 else 0,\n",
    "                \"is_holiday\": 1 if ts.date() in holidays_set else 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def write_to_bigquery(df):\n",
    "    \"\"\"Écrit le dataframe dans BigQuery avec schéma défini.\"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{BQ_DATASET}.forecast_input\"\n",
    "    \n",
    "    # Configuration du job\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    "          schema=[\n",
    "            bigquery.SchemaField(\"pickup_community_area\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"timestamp_hour\", \"TIMESTAMP\"),  # <-- TIMESTAMP ici\n",
    "            bigquery.SchemaField(\"hour\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"day_of_week\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"month\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"day_of_year\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"is_weekend\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"is_holiday\", \"INTEGER\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Chargement des données\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    job.result()  # Attendre la fin du job\n",
    "    \n",
    "    return table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca45009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des données d'entrée pour la prédiction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavevernay/Desktop/Projets/Pro/Avisia/chicago-taxi-genai-demo/venv/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données générées: 1848 lignes, 8 colonnes\n",
      "\n",
      "Aperçu des données d'entrée:\n",
      "  pickup_community_area      timestamp_hour  hour  day_of_week  month  \\\n",
      "0                     1 2025-04-16 12:00:00    12            2      4   \n",
      "1                     1 2025-04-16 13:00:00    13            2      4   \n",
      "2                     1 2025-04-16 14:00:00    14            2      4   \n",
      "3                     1 2025-04-16 15:00:00    15            2      4   \n",
      "4                     1 2025-04-16 16:00:00    16            2      4   \n",
      "\n",
      "   day_of_year  is_weekend  is_holiday  \n",
      "0          106           0           0  \n",
      "1          106           0           0  \n",
      "2          106           0           0  \n",
      "3          106           0           0  \n",
      "4          106           0           0  \n",
      "\n",
      "Export des données vers BigQuery...\n",
      "✅ Données exportées vers la table: avisia-certification-ml-yde.chicago_taxis.forecast_input\n"
     ]
    }
   ],
   "source": [
    "# Génération des données d'entrée pour la prédiction\n",
    "print(\"Génération des données d'entrée pour la prédiction...\")\n",
    "df_input = generate_forecast_input()\n",
    "df_input['timestamp_hour'] = pd.to_datetime(df_input['timestamp_hour'])\n",
    "df_input['pickup_community_area'] = df_input['pickup_community_area'].astype(str)\n",
    "\n",
    "print(f\"✅ Données générées: {df_input.shape[0]} lignes, {df_input.shape[1]} colonnes\")\n",
    "\n",
    "# Aperçu des données générées\n",
    "print(\"\\nAperçu des données d'entrée:\")\n",
    "print(df_input.head(5))\n",
    "\n",
    "# Export vers BigQuery\n",
    "try:\n",
    "    print(\"\\nExport des données vers BigQuery...\")\n",
    "    table_id = write_to_bigquery(df_input)\n",
    "    print(f\"✅ Données exportées vers la table: {table_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de l'export vers BigQuery: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cd64d",
   "metadata": {},
   "source": [
    "## 5. Chargement du Modèle Entraîné\n",
    "\n",
    "Chargeons le modèle de prévision entraîné depuis Vertex AI Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34bd8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche du modèle le plus récent avec le préfixe: 'chicago_taxi_forecast_model'\n",
      "✅ Modèle trouvé: chicago_taxi_forecast_model_20250415_1127 (Resource Name: projects/807699310940/locations/europe-west1/models/988694049835712512, créé le 2025-04-15 09:27:35.570357+00:00)\n"
     ]
    }
   ],
   "source": [
    "# Récupération du modèle le plus récent\n",
    "# Utiliser le préfixe défini dans la configuration pour la recherche\n",
    "model_prefix = config.get(\"model_registry\", {}).get(\"model_display_name_prefix\", \"chicago_taxi_forecast_model\")\n",
    "print(f\"Recherche du modèle le plus récent avec le préfixe: '{model_prefix}'\")\n",
    "\n",
    "try:\n",
    "    # Rechercher les modèles dont le nom commence par le préfixe\n",
    "    # Note: L'API ne supporte pas directement 'LIKE' ou 'STARTS_WITH' dans le filtre standard.\n",
    "    # On liste donc tous les modèles (ou un sous-ensemble si possible) et on filtre côté client,\n",
    "    # ou on utilise un nom exact si la pipeline l'enregistre de manière prédictible.\n",
    "    # Alternative: Utiliser un nom exact si connu ou le récupérer depuis la sortie de la pipeline HPT.\n",
    "\n",
    "    # Stratégie 1: Lister avec un filtre plus large et trier/filtrer ensuite (peut être lent si bcp de modèles)\n",
    "    # models = aiplatform.Model.list(order_by=\"create_time desc\")\n",
    "    # matching_models = [m for m in models if m.display_name.startswith(model_prefix)]\n",
    "\n",
    "    # Stratégie 2: Essayer de récupérer le modèle via une sortie de pipeline (plus robuste si disponible)\n",
    "    # Si l'URI du modèle est passé d'une étape précédente (ex: sortie de HPT job), l'utiliser directement:\n",
    "    # model_resource_name = \"URI_OU_NOM_COMPLET_DU_MODELE_DE_LA_PIPELINE\"\n",
    "    # model = aiplatform.Model(model_name=model_resource_name)\n",
    "    # print(f\"✅ Modèle chargé directement via resource name: {model.display_name}\")\n",
    "\n",
    "    # Stratégie 3: Utiliser list avec un nom exact si la convention de nommage est fixe.\n",
    "    # Supposons que le dernier modèle HPT enregistré ait un nom prédictible ou soit taggué 'latest'.\n",
    "    # Pour cet exemple, on va chercher les modèles commençant par le préfixe et prendre le plus récent.\n",
    "    \n",
    "    all_models = aiplatform.Model.list(order_by=\"create_time desc\")\n",
    "    models = [m for m in all_models if m.display_name.startswith(model_prefix)]\n",
    "\n",
    "    if models:\n",
    "        model = models[0]  # Prendre le plus récent correspondant au préfixe\n",
    "        print(f\"✅ Modèle trouvé: {model.display_name} (Resource Name: {model.resource_name}, créé le {model.create_time})\")\n",
    "        # Stocker le nom de ressource pour le job batch (plus fiable que display_name)\n",
    "        model_resource_name = model.resource_name\n",
    "    else:\n",
    "        # Si aucun modèle n'est trouvé avec le préfixe\n",
    "        raise ValueError(f\"Aucun modèle trouvé avec le préfixe '{model_prefix}'. Vérifiez le nom dans config/pipeline_config.yaml et si la pipeline d'entraînement a bien enregistré un modèle.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors du chargement du modèle: {e}\")\n",
    "    # Réinitialiser la variable modèle en cas d'erreur\n",
    "    model = None\n",
    "    model_resource_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d178676",
   "metadata": {},
   "source": [
    "## 6. Lancement de la Prédiction Batch\n",
    "\n",
    "Utilisons le modèle pour générer des prédictions sur les données futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a18ee272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Lancement du job de prédiction batch...\n",
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/europe-west1/batch-predictions/9173784131161554944?project=807699310940\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/807699310940/locations/europe-west1/batchPredictionJobs/9173784131161554944\n",
      "✅ Prédictions générées avec succès!\n",
      "Les résultats sont stockés dans: avisia-certification-ml-yde.chicago_taxis\n"
     ]
    }
   ],
   "source": [
    "# Nom du job de prédiction batch\n",
    "batch_job_name = f\"batch_pred_taxi_demand_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "try:\n",
    "    # Lancement du job de prédiction batch\n",
    "    print(f\"⏳ Lancement du job de prédiction batch...\")\n",
    "    batch_job = model.batch_predict(\n",
    "        job_display_name=batch_job_name,\n",
    "        instances_format=\"bigquery\",\n",
    "        predictions_format=\"bigquery\",\n",
    "        bigquery_source=BQ_INPUT,\n",
    "        bigquery_destination_prefix=BQ_OUTPUT,\n",
    "        sync=True,  # Mode synchrone: attend la fin du job\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Prédictions générées avec succès!\")\n",
    "    print(f\"Les résultats sont stockés dans: {BQ_OUTPUT}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la prédiction batch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ca02d",
   "metadata": {},
   "source": [
    "## 7. Récupération et Analyse des Résultats\n",
    "\n",
    "Récupérons les résultats des prédictions de BigQuery et analysons-les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a09adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentative de requête avec le client BigQuery par défaut pour la table: avisia-certification-ml-yde.chicago_taxis.predictions_2025_04_16T02_38_20_413Z_934\n",
      "❌ Erreur lors de la récupération des prédictions: 400 Unrecognized name: instance at [3:7]; reason: invalidQuery, location: query, message: Unrecognized name: instance at [3:7]\n",
      "\n",
      "Location: europe-west1\n",
      "Job ID: 567fa871-41df-461d-b149-45099cc2acfe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Récupération et analyse des résultats de prédiction batch\n",
    "\n",
    "# Après le batch_predict, récupère le nom de la table de sortie :\n",
    "output_table_uri = batch_job.output_info.bigquery_output_table  # ex: bq://avisia-certification-ml-yde.chicago_taxis.predictions_2025_04_16T02_38_20_413Z_934\n",
    "\n",
    "try:\n",
    "    # Toujours parser l'URI pour obtenir projet, dataset, table\n",
    "    if output_table_uri.startswith(\"bq://\"):\n",
    "        output_table_parts = output_table_uri.replace(\"bq://\", \"\").split(\".\")\n",
    "        if len(output_table_parts) == 3:\n",
    "            output_project, output_dataset, output_table = output_table_parts\n",
    "            output_table_id = f\"{output_project}.{output_dataset}.{output_table}\"\n",
    "        elif len(output_table_parts) == 1:\n",
    "            # Cas très rare, on reconstruit avec le dataset par défaut\n",
    "            output_project = PROJECT_ID\n",
    "            output_dataset = BQ_DATASET\n",
    "            output_table = output_table_parts[0]\n",
    "            output_table_id = f\"{output_project}.{output_dataset}.{output_table}\"\n",
    "        else:\n",
    "            raise ValueError(f\"URI de table inattendue : {output_table_uri}\")\n",
    "    else:\n",
    "        output_project = PROJECT_ID\n",
    "        output_dataset = BQ_DATASET\n",
    "        output_table = output_table_uri\n",
    "        output_table_id = f\"{output_project}.{output_dataset}.{output_table}\"\n",
    "\n",
    "    # Essayer avec le client BigQuery par défaut (initialisé plus haut sans location)\n",
    "    print(f\"Tentative de requête avec le client BigQuery par défaut pour la table: {output_table_id}\")\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      pickup_community_area,\n",
    "      timestamp_hour,\n",
    "      hour,\n",
    "      day_of_week,\n",
    "      is_weekend,\n",
    "      prediction.value[OFFSET(0)] AS predicted_trip_count\n",
    "    FROM `{output_table_id}`\n",
    "    ORDER BY timestamp_hour, pickup_community_area\n",
    "    \"\"\"\n",
    "    # Utiliser le client 'client' initialisé au début du notebook\n",
    "    df_pred = client.query(query).to_dataframe()\n",
    "\n",
    "    # Conversion des types\n",
    "    df_pred['timestamp_hour'] = pd.to_datetime(df_pred['timestamp_hour'])\n",
    "    df_pred['predicted_trip_count'] = df_pred['predicted_trip_count'].astype(float)\n",
    "\n",
    "    print(f\"✅ Prédictions récupérées: {df_pred.shape[0]} lignes\")\n",
    "\n",
    "    # Statistiques descriptives\n",
    "    print(\"\\nStatistiques des prédictions:\")\n",
    "    print(df_pred['predicted_trip_count'].describe())\n",
    "\n",
    "    # Aperçu des prédictions\n",
    "    print(\"\\nAperçu des prédictions:\")\n",
    "    display(df_pred.head())\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la récupération des prédictions: {e}\")\n",
    "    # Si l'erreur persiste, il faudra vérifier la localisation réelle du dataset 'chicago_taxis'\n",
    "    # et potentiellement gérer une requête inter-régions explicitement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c505d99",
   "metadata": {},
   "source": [
    "## 8. Visualisation des Prévisions\n",
    "\n",
    "Visualisons les prévisions pour les zones les plus actives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e480aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de la visualisation des prévisions: name 'df_pred' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavevernay/Desktop/Projets/Pro/Avisia/chicago-taxi-genai-demo/venv/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Identifier les zones les plus actives\n",
    "top_zones_query = f\"\"\"\n",
    "SELECT pickup_community_area, SUM(trip_count) as total_trips\n",
    "FROM `{PROJECT_ID}.{BQ_DATASET}.demand_by_hour`\n",
    "GROUP BY pickup_community_area\n",
    "ORDER BY total_trips DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Récupérer les top zones\n",
    "    top_zones_df = client.query(top_zones_query).to_dataframe()\n",
    "    top_zones = top_zones_df['pickup_community_area'].tolist()\n",
    "    \n",
    "    # Filtrer les prédictions pour ces zones\n",
    "    df_filtered = df_pred[df_pred['pickup_community_area'].isin(top_zones)]\n",
    "    \n",
    "    # Visualisation avec Matplotlib/Seaborn\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.lineplot(\n",
    "        data=df_filtered, \n",
    "        x='timestamp_hour', \n",
    "        y='predicted_trip_count', \n",
    "        hue='pickup_community_area',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Prévision du nombre de courses par heure (5 zones principales)', fontsize=16)\n",
    "    plt.xlabel('Heure de prévision', fontsize=14)\n",
    "    plt.ylabel('Nombre de courses prévues', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualisation interactive avec Plotly\n",
    "    fig = px.line(\n",
    "        df_filtered, \n",
    "        x='timestamp_hour', \n",
    "        y='predicted_trip_count', \n",
    "        color='pickup_community_area',\n",
    "        title='Prévision du nombre de courses par heure (interactive)',\n",
    "        labels={\n",
    "            'timestamp_hour': 'Heure de prévision',\n",
    "            'predicted_trip_count': 'Nombre de courses prévues',\n",
    "            'pickup_community_area': 'Zone de prise en charge'\n",
    "        }\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Heure de prévision',\n",
    "        yaxis_title='Nombre de courses prévues',\n",
    "        legend_title='Zone',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de la visualisation des prévisions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10985d",
   "metadata": {},
   "source": [
    "## 9. Analyse des Patterns Horaires\n",
    "\n",
    "Analysons les patterns horaires des prévisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd75031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de l'analyse des patterns horaires: name 'df_pred' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Analyse par heure de la journée\n",
    "try:\n",
    "    # Agréger les prévisions par heure\n",
    "    hourly_pred = df_pred.groupby('hour')['predicted_trip_count'].mean().reset_index()\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(x='hour', y='predicted_trip_count', data=hourly_pred, palette='viridis')\n",
    "    plt.title('Nombre Moyen de Courses Prévues par Heure de la Journée', fontsize=16)\n",
    "    plt.xlabel('Heure (0-23)', fontsize=14)\n",
    "    plt.ylabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.xticks(range(24))\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse par jour de la semaine et heure\n",
    "    day_hour_pred = df_pred.groupby(['day_of_week', 'hour'])['predicted_trip_count'].mean().reset_index()\n",
    "    day_hour_pivot = day_hour_pred.pivot(index='hour', columns='day_of_week', values='predicted_trip_count')\n",
    "    \n",
    "    # Renommer les colonnes pour plus de clarté\n",
    "    day_names = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "    day_hour_pivot.columns = [day_names[int(day)] for day in day_hour_pivot.columns]\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(\n",
    "        day_hour_pivot, \n",
    "        cmap='viridis', \n",
    "        annot=True, \n",
    "        fmt='.1f',\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    plt.title('Nombre Moyen de Courses Prévues par Jour et Heure', fontsize=16)\n",
    "    plt.xlabel('Jour de la Semaine', fontsize=14)\n",
    "    plt.ylabel('Heure de la Journée', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de l'analyse des patterns horaires: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d9f09",
   "metadata": {},
   "source": [
    "## 10. Analyse Spatiale des Prévisions\n",
    "\n",
    "Analysons la distribution spatiale des prévisions par zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbf8273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de l'analyse spatiale: name 'df_pred' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Agrégation par zone\n",
    "try:\n",
    "    zone_pred = df_pred.groupby('pickup_community_area')['predicted_trip_count'].mean().reset_index()\n",
    "    zone_pred = zone_pred.sort_values('predicted_trip_count', ascending=False)\n",
    "    \n",
    "    # Top 15 zones les plus actives\n",
    "    top_15_zones = zone_pred.head(15)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.barplot(\n",
    "        x='pickup_community_area', \n",
    "        y='predicted_trip_count', \n",
    "        data=top_15_zones,\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('15 Zones avec le Plus Grand Nombre Moyen de Courses Prévues', fontsize=16)\n",
    "    plt.xlabel('Zone (pickup_community_area)', fontsize=14)\n",
    "    plt.ylabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Distribution des prévisions à travers toutes les zones\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.histplot(zone_pred['predicted_trip_count'], bins=30, kde=True)\n",
    "    plt.title('Distribution du Nombre Moyen de Courses Prévues par Zone', fontsize=16)\n",
    "    plt.xlabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.ylabel('Nombre de Zones', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de l'analyse spatiale: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaeb88a",
   "metadata": {},
   "source": [
    "## 11. Comparaison Weekend vs. Jours de Semaine\n",
    "\n",
    "Comparons les prévisions pour les weekends et les jours de semaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a45a3373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Erreur lors de la comparaison weekend vs. semaine: name 'df_pred' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Agrégation par heure et weekend/semaine\n",
    "    weekend_hourly = df_pred.groupby(['hour', 'is_weekend'])['predicted_trip_count'].mean().reset_index()\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.lineplot(\n",
    "        data=weekend_hourly, \n",
    "        x='hour', \n",
    "        y='predicted_trip_count', \n",
    "        hue='is_weekend',\n",
    "        palette=['#1f77b4', '#ff7f0e'],\n",
    "        markers=['o', 's'],\n",
    "        style='is_weekend',\n",
    "        linewidth=2.5\n",
    "    )\n",
    "    plt.title('Nombre Moyen de Courses Prévues par Heure: Weekend vs. Semaine', fontsize=16)\n",
    "    plt.xlabel('Heure de la Journée', fontsize=14)\n",
    "    plt.ylabel('Nombre Moyen de Courses Prévues', fontsize=14)\n",
    "    plt.xticks(range(24))\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(labels=['Semaine', 'Weekend'], title='Période')\n",
    "    plt.show()\n",
    "    \n",
    "    # Comparaison pour les zones principales\n",
    "    if 'top_zones' in locals():\n",
    "        top_zone_weekend = df_pred[df_pred['pickup_community_area'].isin(top_zones[:3])]\n",
    "        \n",
    "        g = sns.FacetGrid(\n",
    "            top_zone_weekend, \n",
    "            col='pickup_community_area', \n",
    "            hue='is_weekend',\n",
    "            col_wrap=1, \n",
    "            height=4, \n",
    "            aspect=3,\n",
    "            sharex=True\n",
    "        )\n",
    "        g.map(sns.lineplot, 'hour', 'predicted_trip_count')\n",
    "        g.add_legend(labels=['Semaine', 'Weekend'])\n",
    "        g.set_axis_labels('Heure de la Journée', 'Nombre de Courses Prévues')\n",
    "        g.set_titles('Zone {col_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erreur lors de la comparaison weekend vs. semaine: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86ef97",
   "metadata": {},
   "source": [
    "## 12. Conclusion et Prochaines Étapes\n",
    "\n",
    "### Résumé des Analyses\n",
    "- Nous avons généré des prévisions de demande de taxis pour les périodes futures\n",
    "- Les visualisations temporelles montrent des patterns clairs par heure et par jour\n",
    "- L'analyse spatiale identifie les zones avec la plus forte demande prévue\n",
    "- La comparaison weekend vs. semaine révèle des différences significatives dans les patterns de demande\n",
    "\n",
    "### Insights Métier\n",
    "- Les heures de pointe pour la demande de taxis sont principalement le matin et le soir en semaine\n",
    "- Le weekend montre une demande plus élevée en soirée et la nuit\n",
    "- Certaines zones ont une demande significativement plus élevée que d'autres\n",
    "- Ces informations peuvent aider à optimiser l'allocation des taxis dans le temps et l'espace\n",
    "\n",
    "### Prochaines Étapes\n",
    "- Intégrer des données météorologiques et d'événements pour améliorer les prévisions\n",
    "- Développer un tableau de bord en temps réel pour suivre les prévisions\n",
    "- Explorer des stratégies d'optimisation de la flotte basées sur ces prévisions\n",
    "- Évaluer et raffiner régulièrement le modèle avec de nouvelles données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
